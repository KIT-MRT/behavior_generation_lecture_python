
<!doctype html>
<html lang="en" class="no-js">
  <head>
    
      <meta charset="utf-8">
      <meta name="viewport" content="width=device-width,initial-scale=1">
      
        <meta name="description" content="Python Code for the Lecture Decision-Making and Motion Planning for Automated Driving at KIT">
      
      
        <meta name="author" content="Organizers of the lecture Decision-Making and Motion Planning for Automated Driving at KIT">
      
      
      
        <link rel="prev" href="../">
      
      
        <link rel="next" href="../policy/">
      
      
      <link rel="icon" href="../../../../assets/images/favicon.png">
      <meta name="generator" content="mkdocs-1.6.1, mkdocs-material-9.5.49">
    
    
      
        <title>mdp - Behavior Generation Lecture Python</title>
      
    
    
      <link rel="stylesheet" href="../../../../assets/stylesheets/main.6f8fc17f.min.css">
      
      


    
    
      
    
    
      
    
    
      <link rel="stylesheet" href="../../../../assets/_mkdocstrings.css">
    
    <script>__md_scope=new URL("../../../..",location),__md_hash=e=>[...e].reduce(((e,_)=>(e<<5)-e+_.charCodeAt(0)),0),__md_get=(e,_=localStorage,t=__md_scope)=>JSON.parse(_.getItem(t.pathname+"."+e)),__md_set=(e,_,t=localStorage,a=__md_scope)=>{try{t.setItem(a.pathname+"."+e,JSON.stringify(_))}catch(e){}}</script>
    
      

    
    
    
  </head>
  
  
    <body dir="ltr">
  
    
    <input class="md-toggle" data-md-toggle="drawer" type="checkbox" id="__drawer" autocomplete="off">
    <input class="md-toggle" data-md-toggle="search" type="checkbox" id="__search" autocomplete="off">
    <label class="md-overlay" for="__drawer"></label>
    <div data-md-component="skip">
      
        
        <a href="#behavior_generation_lecture_python.mdp.mdp" class="md-skip">
          Skip to content
        </a>
      
    </div>
    <div data-md-component="announce">
      
    </div>
    
    
      

  

<header class="md-header md-header--shadow" data-md-component="header">
  <nav class="md-header__inner md-grid" aria-label="Header">
    <a href="../../../.." title="Behavior Generation Lecture Python" class="md-header__button md-logo" aria-label="Behavior Generation Lecture Python" data-md-component="logo">
      
  
  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 8a3 3 0 0 0 3-3 3 3 0 0 0-3-3 3 3 0 0 0-3 3 3 3 0 0 0 3 3m0 3.54C9.64 9.35 6.5 8 3 8v11c3.5 0 6.64 1.35 9 3.54 2.36-2.19 5.5-3.54 9-3.54V8c-3.5 0-6.64 1.35-9 3.54"/></svg>

    </a>
    <label class="md-header__button md-icon" for="__drawer">
      
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M3 6h18v2H3zm0 5h18v2H3zm0 5h18v2H3z"/></svg>
    </label>
    <div class="md-header__title" data-md-component="header-title">
      <div class="md-header__ellipsis">
        <div class="md-header__topic">
          <span class="md-ellipsis">
            Behavior Generation Lecture Python
          </span>
        </div>
        <div class="md-header__topic" data-md-component="header-topic">
          <span class="md-ellipsis">
            
              mdp
            
          </span>
        </div>
      </div>
    </div>
    
    
      <script>var palette=__md_get("__palette");if(palette&&palette.color){if("(prefers-color-scheme)"===palette.color.media){var media=matchMedia("(prefers-color-scheme: light)"),input=document.querySelector(media.matches?"[data-md-color-media='(prefers-color-scheme: light)']":"[data-md-color-media='(prefers-color-scheme: dark)']");palette.color.media=input.getAttribute("data-md-color-media"),palette.color.scheme=input.getAttribute("data-md-color-scheme"),palette.color.primary=input.getAttribute("data-md-color-primary"),palette.color.accent=input.getAttribute("data-md-color-accent")}for(var[key,value]of Object.entries(palette.color))document.body.setAttribute("data-md-color-"+key,value)}</script>
    
    
    
      <label class="md-header__button md-icon" for="__search">
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.52 6.52 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5"/></svg>
      </label>
      <div class="md-search" data-md-component="search" role="dialog">
  <label class="md-search__overlay" for="__search"></label>
  <div class="md-search__inner" role="search">
    <form class="md-search__form" name="search">
      <input type="text" class="md-search__input" name="query" aria-label="Search" placeholder="Search" autocapitalize="off" autocorrect="off" autocomplete="off" spellcheck="false" data-md-component="search-query" required>
      <label class="md-search__icon md-icon" for="__search">
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.52 6.52 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5"/></svg>
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11z"/></svg>
      </label>
      <nav class="md-search__options" aria-label="Search">
        
        <button type="reset" class="md-search__icon md-icon" title="Clear" aria-label="Clear" tabindex="-1">
          
          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M19 6.41 17.59 5 12 10.59 6.41 5 5 6.41 10.59 12 5 17.59 6.41 19 12 13.41 17.59 19 19 17.59 13.41 12z"/></svg>
        </button>
      </nav>
      
    </form>
    <div class="md-search__output">
      <div class="md-search__scrollwrap" tabindex="0" data-md-scrollfix>
        <div class="md-search-result" data-md-component="search-result">
          <div class="md-search-result__meta">
            Initializing search
          </div>
          <ol class="md-search-result__list" role="presentation"></ol>
        </div>
      </div>
    </div>
  </div>
</div>
    
    
      <div class="md-header__source">
        <a href="https://github.com/KIT-MRT/behavior_generation_lecture_python" title="Go to repository" class="md-source" data-md-component="source">
  <div class="md-source__icon md-icon">
    
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512"><!--! Font Awesome Free 6.7.1 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2024 Fonticons, Inc.--><path d="M439.55 236.05 244 40.45a28.87 28.87 0 0 0-40.81 0l-40.66 40.63 51.52 51.52c27.06-9.14 52.68 16.77 43.39 43.68l49.66 49.66c34.23-11.8 61.18 31 35.47 56.69-26.49 26.49-70.21-2.87-56-37.34L240.22 199v121.85c25.3 12.54 22.26 41.85 9.08 55a34.34 34.34 0 0 1-48.55 0c-17.57-17.6-11.07-46.91 11.25-56v-123c-20.8-8.51-24.6-30.74-18.64-45L142.57 101 8.45 235.14a28.86 28.86 0 0 0 0 40.81l195.61 195.6a28.86 28.86 0 0 0 40.8 0l194.69-194.69a28.86 28.86 0 0 0 0-40.81"/></svg>
  </div>
  <div class="md-source__repository">
    KIT-MRT/behavior_generation_lecture_python
  </div>
</a>
      </div>
    
  </nav>
  
</header>
    
    <div class="md-container" data-md-component="container">
      
      
        
          
        
      
      <main class="md-main" data-md-component="main">
        <div class="md-main__inner md-grid">
          
            
              
              <div class="md-sidebar md-sidebar--primary" data-md-component="sidebar" data-md-type="navigation" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    



<nav class="md-nav md-nav--primary" aria-label="Navigation" data-md-level="0">
  <label class="md-nav__title" for="__drawer">
    <a href="../../../.." title="Behavior Generation Lecture Python" class="md-nav__button md-logo" aria-label="Behavior Generation Lecture Python" data-md-component="logo">
      
  
  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 8a3 3 0 0 0 3-3 3 3 0 0 0-3-3 3 3 0 0 0-3 3 3 3 0 0 0 3 3m0 3.54C9.64 9.35 6.5 8 3 8v11c3.5 0 6.64 1.35 9 3.54 2.36-2.19 5.5-3.54 9-3.54V8c-3.5 0-6.64 1.35-9 3.54"/></svg>

    </a>
    Behavior Generation Lecture Python
  </label>
  
    <div class="md-nav__source">
      <a href="https://github.com/KIT-MRT/behavior_generation_lecture_python" title="Go to repository" class="md-source" data-md-component="source">
  <div class="md-source__icon md-icon">
    
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512"><!--! Font Awesome Free 6.7.1 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2024 Fonticons, Inc.--><path d="M439.55 236.05 244 40.45a28.87 28.87 0 0 0-40.81 0l-40.66 40.63 51.52 51.52c27.06-9.14 52.68 16.77 43.39 43.68l49.66 49.66c34.23-11.8 61.18 31 35.47 56.69-26.49 26.49-70.21-2.87-56-37.34L240.22 199v121.85c25.3 12.54 22.26 41.85 9.08 55a34.34 34.34 0 0 1-48.55 0c-17.57-17.6-11.07-46.91 11.25-56v-123c-20.8-8.51-24.6-30.74-18.64-45L142.57 101 8.45 235.14a28.86 28.86 0 0 0 0 40.81l195.61 195.6a28.86 28.86 0 0 0 40.8 0l194.69-194.69a28.86 28.86 0 0 0 0-40.81"/></svg>
  </div>
  <div class="md-source__repository">
    KIT-MRT/behavior_generation_lecture_python
  </div>
</a>
    </div>
  
  <ul class="md-nav__list" data-md-scrollfix>
    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../.." class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Home
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
  
  
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_2" >
        
          
          <label class="md-nav__link" for="__nav_2" id="__nav_2_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    Code Examples for Lecture
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_2_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_2">
            <span class="md-nav__icon md-icon"></span>
            Code Examples for Lecture
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../../notebooks/compare_models_notebook/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Compare Dynamic One Track Models
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../../notebooks/lateral_control_state_based_notebook/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Lateral Control (state-based)
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../../notebooks/lateral_control_riccati_notebook/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Lateral Control (Riccati)
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../../notebooks/a_star_notebook/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Graph Search
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_2_5" >
        
          
          <label class="md-nav__link" for="__nav_2_5" id="__nav_2_5_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    Decision Making
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_2_5_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_2_5">
            <span class="md-nav__icon md-icon"></span>
            Decision Making
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../../notebooks/mdp_value_iteration/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Value Iteration
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../../notebooks/mdp_q_learning/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Q-Learning
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../../notebooks/mdp_policy_gradient/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Policy Gradient
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
      
      
  
  
    
  
  
  
    
    
    
    
    <li class="md-nav__item md-nav__item--active md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_3" checked>
        
          
          <label class="md-nav__link" for="__nav_3" id="__nav_3_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    API Documentation (partial)
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_3_label" aria-expanded="true">
          <label class="md-nav__title" for="__nav_3">
            <span class="md-nav__icon md-icon"></span>
            API Documentation (partial)
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
    
  
  
  
    
    
    
    
    <li class="md-nav__item md-nav__item--active md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_3_1" checked>
        
          
          <label class="md-nav__link" for="__nav_3_1" id="__nav_3_1_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    behavior_generation_lecture_python
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_3_1_label" aria-expanded="true">
          <label class="md-nav__title" for="__nav_3_1">
            <span class="md-nav__icon md-icon"></span>
            behavior_generation_lecture_python
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_3_1_1" >
        
          
          
          <div class="md-nav__link md-nav__container">
            <a href="../../graph_search/" class="md-nav__link ">
              
  
  <span class="md-ellipsis">
    graph_search
  </span>
  

            </a>
            
              
              <label class="md-nav__link " for="__nav_3_1_1" id="__nav_3_1_1_label" tabindex="0">
                <span class="md-nav__icon md-icon"></span>
              </label>
            
          </div>
        
        <nav class="md-nav" data-md-level="3" aria-labelledby="__nav_3_1_1_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_3_1_1">
            <span class="md-nav__icon md-icon"></span>
            graph_search
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../graph_search/a_star/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    a_star
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
    
  
  
  
    
    
    
    
    <li class="md-nav__item md-nav__item--active md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_3_1_2" checked>
        
          
          
          <div class="md-nav__link md-nav__container">
            <a href="../" class="md-nav__link ">
              
  
  <span class="md-ellipsis">
    mdp
  </span>
  

            </a>
            
              
              <label class="md-nav__link " for="__nav_3_1_2" id="__nav_3_1_2_label" tabindex="0">
                <span class="md-nav__icon md-icon"></span>
              </label>
            
          </div>
        
        <nav class="md-nav" data-md-level="3" aria-labelledby="__nav_3_1_2_label" aria-expanded="true">
          <label class="md-nav__title" for="__nav_3_1_2">
            <span class="md-nav__icon md-icon"></span>
            mdp
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
    
  
  
  
    <li class="md-nav__item md-nav__item--active">
      
      <input class="md-nav__toggle md-toggle" type="checkbox" id="__toc">
      
      
      
        <label class="md-nav__link md-nav__link--active" for="__toc">
          
  
  <span class="md-ellipsis">
    mdp
  </span>
  

          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <a href="./" class="md-nav__link md-nav__link--active">
        
  
  <span class="md-ellipsis">
    mdp
  </span>
  

      </a>
      
        

<nav class="md-nav md-nav--secondary" aria-label="Table of contents">
  
  
  
  
    <label class="md-nav__title" for="__toc">
      <span class="md-nav__icon md-icon"></span>
      Table of contents
    </label>
    <ul class="md-nav__list" data-md-component="toc" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#behavior_generation_lecture_python.mdp.mdp" class="md-nav__link">
    <span class="md-ellipsis">
      mdp
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#behavior_generation_lecture_python.mdp.mdp.GridMDP" class="md-nav__link">
    <span class="md-ellipsis">
      GridMDP
    </span>
  </a>
  
    <nav class="md-nav" aria-label="GridMDP">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#behavior_generation_lecture_python.mdp.mdp.GridMDP.__init__" class="md-nav__link">
    <span class="md-ellipsis">
      __init__
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#behavior_generation_lecture_python.mdp.mdp.MDP" class="md-nav__link">
    <span class="md-ellipsis">
      MDP
    </span>
  </a>
  
    <nav class="md-nav" aria-label="MDP">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#behavior_generation_lecture_python.mdp.mdp.MDP.__init__" class="md-nav__link">
    <span class="md-ellipsis">
      __init__
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#behavior_generation_lecture_python.mdp.mdp.MDP.execute_action" class="md-nav__link">
    <span class="md-ellipsis">
      execute_action
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#behavior_generation_lecture_python.mdp.mdp.MDP.get_actions" class="md-nav__link">
    <span class="md-ellipsis">
      get_actions
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#behavior_generation_lecture_python.mdp.mdp.MDP.get_reward" class="md-nav__link">
    <span class="md-ellipsis">
      get_reward
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#behavior_generation_lecture_python.mdp.mdp.MDP.get_states" class="md-nav__link">
    <span class="md-ellipsis">
      get_states
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#behavior_generation_lecture_python.mdp.mdp.MDP.get_transitions_with_probabilities" class="md-nav__link">
    <span class="md-ellipsis">
      get_transitions_with_probabilities
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#behavior_generation_lecture_python.mdp.mdp.MDP.is_terminal" class="md-nav__link">
    <span class="md-ellipsis">
      is_terminal
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#behavior_generation_lecture_python.mdp.mdp.MDP.sample_next_state" class="md-nav__link">
    <span class="md-ellipsis">
      sample_next_state
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#behavior_generation_lecture_python.mdp.mdp.PolicyGradientBuffer" class="md-nav__link">
    <span class="md-ellipsis">
      PolicyGradientBuffer
    </span>
  </a>
  
    <nav class="md-nav" aria-label="PolicyGradientBuffer">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#behavior_generation_lecture_python.mdp.mdp.PolicyGradientBuffer.mean_episode_length" class="md-nav__link">
    <span class="md-ellipsis">
      mean_episode_length
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#behavior_generation_lecture_python.mdp.mdp.PolicyGradientBuffer.mean_episode_return" class="md-nav__link">
    <span class="md-ellipsis">
      mean_episode_return
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#behavior_generation_lecture_python.mdp.mdp.best_action_from_q_table" class="md-nav__link">
    <span class="md-ellipsis">
      best_action_from_q_table
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#behavior_generation_lecture_python.mdp.mdp.derive_deterministic_policy" class="md-nav__link">
    <span class="md-ellipsis">
      derive_deterministic_policy
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#behavior_generation_lecture_python.mdp.mdp.derive_policy" class="md-nav__link">
    <span class="md-ellipsis">
      derive_policy
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#behavior_generation_lecture_python.mdp.mdp.expected_utility_of_action" class="md-nav__link">
    <span class="md-ellipsis">
      expected_utility_of_action
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#behavior_generation_lecture_python.mdp.mdp.greedy_value_estimate_for_state" class="md-nav__link">
    <span class="md-ellipsis">
      greedy_value_estimate_for_state
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#behavior_generation_lecture_python.mdp.mdp.policy_gradient" class="md-nav__link">
    <span class="md-ellipsis">
      policy_gradient
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#behavior_generation_lecture_python.mdp.mdp.q_learning" class="md-nav__link">
    <span class="md-ellipsis">
      q_learning
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#behavior_generation_lecture_python.mdp.mdp.random_action" class="md-nav__link">
    <span class="md-ellipsis">
      random_action
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#behavior_generation_lecture_python.mdp.mdp.value_iteration" class="md-nav__link">
    <span class="md-ellipsis">
      value_iteration
    </span>
  </a>
  
</li>
      
    </ul>
  
</nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../policy/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    policy
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
  </ul>
</nav>
                  </div>
                </div>
              </div>
            
            
              
              <div class="md-sidebar md-sidebar--secondary" data-md-component="sidebar" data-md-type="toc" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    

<nav class="md-nav md-nav--secondary" aria-label="Table of contents">
  
  
  
  
    <label class="md-nav__title" for="__toc">
      <span class="md-nav__icon md-icon"></span>
      Table of contents
    </label>
    <ul class="md-nav__list" data-md-component="toc" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#behavior_generation_lecture_python.mdp.mdp" class="md-nav__link">
    <span class="md-ellipsis">
      mdp
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#behavior_generation_lecture_python.mdp.mdp.GridMDP" class="md-nav__link">
    <span class="md-ellipsis">
      GridMDP
    </span>
  </a>
  
    <nav class="md-nav" aria-label="GridMDP">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#behavior_generation_lecture_python.mdp.mdp.GridMDP.__init__" class="md-nav__link">
    <span class="md-ellipsis">
      __init__
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#behavior_generation_lecture_python.mdp.mdp.MDP" class="md-nav__link">
    <span class="md-ellipsis">
      MDP
    </span>
  </a>
  
    <nav class="md-nav" aria-label="MDP">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#behavior_generation_lecture_python.mdp.mdp.MDP.__init__" class="md-nav__link">
    <span class="md-ellipsis">
      __init__
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#behavior_generation_lecture_python.mdp.mdp.MDP.execute_action" class="md-nav__link">
    <span class="md-ellipsis">
      execute_action
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#behavior_generation_lecture_python.mdp.mdp.MDP.get_actions" class="md-nav__link">
    <span class="md-ellipsis">
      get_actions
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#behavior_generation_lecture_python.mdp.mdp.MDP.get_reward" class="md-nav__link">
    <span class="md-ellipsis">
      get_reward
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#behavior_generation_lecture_python.mdp.mdp.MDP.get_states" class="md-nav__link">
    <span class="md-ellipsis">
      get_states
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#behavior_generation_lecture_python.mdp.mdp.MDP.get_transitions_with_probabilities" class="md-nav__link">
    <span class="md-ellipsis">
      get_transitions_with_probabilities
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#behavior_generation_lecture_python.mdp.mdp.MDP.is_terminal" class="md-nav__link">
    <span class="md-ellipsis">
      is_terminal
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#behavior_generation_lecture_python.mdp.mdp.MDP.sample_next_state" class="md-nav__link">
    <span class="md-ellipsis">
      sample_next_state
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#behavior_generation_lecture_python.mdp.mdp.PolicyGradientBuffer" class="md-nav__link">
    <span class="md-ellipsis">
      PolicyGradientBuffer
    </span>
  </a>
  
    <nav class="md-nav" aria-label="PolicyGradientBuffer">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#behavior_generation_lecture_python.mdp.mdp.PolicyGradientBuffer.mean_episode_length" class="md-nav__link">
    <span class="md-ellipsis">
      mean_episode_length
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#behavior_generation_lecture_python.mdp.mdp.PolicyGradientBuffer.mean_episode_return" class="md-nav__link">
    <span class="md-ellipsis">
      mean_episode_return
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#behavior_generation_lecture_python.mdp.mdp.best_action_from_q_table" class="md-nav__link">
    <span class="md-ellipsis">
      best_action_from_q_table
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#behavior_generation_lecture_python.mdp.mdp.derive_deterministic_policy" class="md-nav__link">
    <span class="md-ellipsis">
      derive_deterministic_policy
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#behavior_generation_lecture_python.mdp.mdp.derive_policy" class="md-nav__link">
    <span class="md-ellipsis">
      derive_policy
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#behavior_generation_lecture_python.mdp.mdp.expected_utility_of_action" class="md-nav__link">
    <span class="md-ellipsis">
      expected_utility_of_action
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#behavior_generation_lecture_python.mdp.mdp.greedy_value_estimate_for_state" class="md-nav__link">
    <span class="md-ellipsis">
      greedy_value_estimate_for_state
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#behavior_generation_lecture_python.mdp.mdp.policy_gradient" class="md-nav__link">
    <span class="md-ellipsis">
      policy_gradient
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#behavior_generation_lecture_python.mdp.mdp.q_learning" class="md-nav__link">
    <span class="md-ellipsis">
      q_learning
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#behavior_generation_lecture_python.mdp.mdp.random_action" class="md-nav__link">
    <span class="md-ellipsis">
      random_action
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#behavior_generation_lecture_python.mdp.mdp.value_iteration" class="md-nav__link">
    <span class="md-ellipsis">
      value_iteration
    </span>
  </a>
  
</li>
      
    </ul>
  
</nav>
                  </div>
                </div>
              </div>
            
          
          
            <div class="md-content" data-md-component="content">
              <article class="md-content__inner md-typeset">
                
                  


  <h1>mdp</h1>

<div class="doc doc-object doc-module">



<a id="behavior_generation_lecture_python.mdp.mdp"></a>
    <div class="doc doc-contents first">

        <p>This module contains the Markov Decision Process, value iteration, Q learning and policy gradient.</p>








  <div class="doc doc-children">








<div class="doc doc-object doc-class">



<h2 id="behavior_generation_lecture_python.mdp.mdp.GridMDP" class="doc doc-heading">
            <code>GridMDP</code>


</h2>


    <div class="doc doc-contents ">
            <p class="doc doc-class-bases">
              Bases: <code><a class="autorefs autorefs-internal" title="behavior_generation_lecture_python.mdp.mdp.MDP" href="#behavior_generation_lecture_python.mdp.mdp.MDP">MDP</a></code></p>


        <p>A Markov decision process on a grid.</p>






              <details class="quote">
                <summary>Source code in <code>src/behavior_generation_lecture_python/mdp/mdp.py</code></summary>
                <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">171</span>
<span class="normal">172</span>
<span class="normal">173</span>
<span class="normal">174</span>
<span class="normal">175</span>
<span class="normal">176</span>
<span class="normal">177</span>
<span class="normal">178</span>
<span class="normal">179</span>
<span class="normal">180</span>
<span class="normal">181</span>
<span class="normal">182</span>
<span class="normal">183</span>
<span class="normal">184</span>
<span class="normal">185</span>
<span class="normal">186</span>
<span class="normal">187</span>
<span class="normal">188</span>
<span class="normal">189</span>
<span class="normal">190</span>
<span class="normal">191</span>
<span class="normal">192</span>
<span class="normal">193</span>
<span class="normal">194</span>
<span class="normal">195</span>
<span class="normal">196</span>
<span class="normal">197</span>
<span class="normal">198</span>
<span class="normal">199</span>
<span class="normal">200</span>
<span class="normal">201</span>
<span class="normal">202</span>
<span class="normal">203</span>
<span class="normal">204</span>
<span class="normal">205</span>
<span class="normal">206</span>
<span class="normal">207</span>
<span class="normal">208</span>
<span class="normal">209</span>
<span class="normal">210</span>
<span class="normal">211</span>
<span class="normal">212</span>
<span class="normal">213</span>
<span class="normal">214</span>
<span class="normal">215</span>
<span class="normal">216</span>
<span class="normal">217</span>
<span class="normal">218</span>
<span class="normal">219</span>
<span class="normal">220</span>
<span class="normal">221</span>
<span class="normal">222</span>
<span class="normal">223</span>
<span class="normal">224</span>
<span class="normal">225</span>
<span class="normal">226</span>
<span class="normal">227</span>
<span class="normal">228</span>
<span class="normal">229</span>
<span class="normal">230</span>
<span class="normal">231</span>
<span class="normal">232</span>
<span class="normal">233</span>
<span class="normal">234</span>
<span class="normal">235</span>
<span class="normal">236</span>
<span class="normal">237</span>
<span class="normal">238</span>
<span class="normal">239</span>
<span class="normal">240</span>
<span class="normal">241</span>
<span class="normal">242</span>
<span class="normal">243</span>
<span class="normal">244</span>
<span class="normal">245</span>
<span class="normal">246</span>
<span class="normal">247</span>
<span class="normal">248</span>
<span class="normal">249</span>
<span class="normal">250</span>
<span class="normal">251</span>
<span class="normal">252</span>
<span class="normal">253</span>
<span class="normal">254</span>
<span class="normal">255</span>
<span class="normal">256</span>
<span class="normal">257</span>
<span class="normal">258</span>
<span class="normal">259</span>
<span class="normal">260</span>
<span class="normal">261</span>
<span class="normal">262</span>
<span class="normal">263</span>
<span class="normal">264</span>
<span class="normal">265</span>
<span class="normal">266</span>
<span class="normal">267</span>
<span class="normal">268</span>
<span class="normal">269</span>
<span class="normal">270</span>
<span class="normal">271</span>
<span class="normal">272</span>
<span class="normal">273</span>
<span class="normal">274</span>
<span class="normal">275</span>
<span class="normal">276</span>
<span class="normal">277</span>
<span class="normal">278</span>
<span class="normal">279</span>
<span class="normal">280</span>
<span class="normal">281</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">class</span> <span class="nc">GridMDP</span><span class="p">(</span><span class="n">MDP</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;A Markov decision process on a grid.&quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">grid</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="n">List</span><span class="p">[</span><span class="n">Union</span><span class="p">[</span><span class="nb">float</span><span class="p">,</span> <span class="kc">None</span><span class="p">]]],</span>
        <span class="n">initial_state</span><span class="p">:</span> <span class="n">GridState</span><span class="p">,</span>
        <span class="n">terminal_states</span><span class="p">:</span> <span class="n">Set</span><span class="p">[</span><span class="n">GridState</span><span class="p">],</span>
        <span class="n">transition_probabilities_per_action</span><span class="p">:</span> <span class="n">Dict</span><span class="p">[</span>
            <span class="n">GridState</span><span class="p">,</span> <span class="n">List</span><span class="p">[</span><span class="n">Tuple</span><span class="p">[</span><span class="nb">float</span><span class="p">,</span> <span class="n">GridState</span><span class="p">]]</span>
        <span class="p">],</span>
        <span class="n">restrict_actions_to_available_states</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">bool</span><span class="p">]</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;A Markov decision process on a grid.</span>

<span class="sd">        Args:</span>
<span class="sd">            grid: List of lists, containing the rewards of the grid</span>
<span class="sd">                states or None.</span>
<span class="sd">            initial_state: Initial state in the grid.</span>
<span class="sd">            terminal_states: Set of terminal states in the grid.</span>
<span class="sd">            transition_probabilities_per_action: Dictionary of</span>
<span class="sd">                transition probabilities per action, mapping from action</span>
<span class="sd">                to list of tuples (probability, next state).</span>
<span class="sd">            restrict_actions_to_available_states: Whether to restrict</span>
<span class="sd">                actions to those that result in valid next states.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">states</span> <span class="o">=</span> <span class="nb">set</span><span class="p">()</span>
        <span class="n">reward</span> <span class="o">=</span> <span class="p">{}</span>
        <span class="n">grid</span> <span class="o">=</span> <span class="n">grid</span><span class="o">.</span><span class="n">copy</span><span class="p">()</span>
        <span class="n">grid</span><span class="o">.</span><span class="n">reverse</span><span class="p">()</span>  <span class="c1"># y-axis pointing upwards</span>
        <span class="n">rows</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">grid</span><span class="p">)</span>
        <span class="n">cols</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">grid</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">grid</span> <span class="o">=</span> <span class="n">grid</span>
        <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">cols</span><span class="p">):</span>
            <span class="k">for</span> <span class="n">y</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">rows</span><span class="p">):</span>
                <span class="k">if</span> <span class="n">grid</span><span class="p">[</span><span class="n">y</span><span class="p">][</span><span class="n">x</span><span class="p">]</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
                    <span class="n">states</span><span class="o">.</span><span class="n">add</span><span class="p">((</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">))</span>
                    <span class="n">reward_xy</span> <span class="o">=</span> <span class="n">grid</span><span class="p">[</span><span class="n">y</span><span class="p">][</span><span class="n">x</span><span class="p">]</span>
                    <span class="k">assert</span> <span class="n">reward_xy</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span>
                    <span class="n">reward</span><span class="p">[(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">)]</span> <span class="o">=</span> <span class="n">reward_xy</span>

        <span class="n">transition_probabilities</span> <span class="o">=</span> <span class="p">{}</span>
        <span class="k">for</span> <span class="n">state</span> <span class="ow">in</span> <span class="n">states</span><span class="p">:</span>
            <span class="k">for</span> <span class="n">action</span> <span class="ow">in</span> <span class="n">transition_probabilities_per_action</span><span class="o">.</span><span class="n">keys</span><span class="p">():</span>
                <span class="n">transition_probability_list</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_generate_transition_probability_list</span><span class="p">(</span>
                    <span class="n">state</span><span class="o">=</span><span class="n">state</span><span class="p">,</span>
                    <span class="n">action</span><span class="o">=</span><span class="n">action</span><span class="p">,</span>
                    <span class="n">restrict_actions_to_available_states</span><span class="o">=</span><span class="n">restrict_actions_to_available_states</span><span class="p">,</span>
                    <span class="n">states</span><span class="o">=</span><span class="n">states</span><span class="p">,</span>
                    <span class="n">transition_probabilities_per_action</span><span class="o">=</span><span class="n">transition_probabilities_per_action</span><span class="p">,</span>
                    <span class="n">next_state_fn</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">_next_state_deterministic</span><span class="p">,</span>
                <span class="p">)</span>
                <span class="k">if</span> <span class="n">transition_probability_list</span><span class="p">:</span>
                    <span class="n">transition_probabilities</span><span class="p">[(</span><span class="n">state</span><span class="p">,</span> <span class="n">action</span><span class="p">)]</span> <span class="o">=</span> <span class="p">(</span>
                        <span class="n">transition_probability_list</span>
                    <span class="p">)</span>

        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span>
            <span class="n">states</span><span class="o">=</span><span class="n">states</span><span class="p">,</span>
            <span class="n">actions</span><span class="o">=</span><span class="nb">set</span><span class="p">(</span><span class="n">transition_probabilities_per_action</span><span class="o">.</span><span class="n">keys</span><span class="p">()),</span>
            <span class="n">initial_state</span><span class="o">=</span><span class="n">initial_state</span><span class="p">,</span>
            <span class="n">terminal_states</span><span class="o">=</span><span class="n">terminal_states</span><span class="p">,</span>
            <span class="n">transition_probabilities</span><span class="o">=</span><span class="n">transition_probabilities</span><span class="p">,</span>
            <span class="n">reward</span><span class="o">=</span><span class="n">reward</span><span class="p">,</span>
        <span class="p">)</span>

    <span class="nd">@staticmethod</span>
    <span class="k">def</span> <span class="nf">_generate_transition_probability_list</span><span class="p">(</span>
        <span class="n">state</span><span class="p">,</span>
        <span class="n">action</span><span class="p">,</span>
        <span class="n">restrict_actions_to_available_states</span><span class="p">,</span>
        <span class="n">states</span><span class="p">,</span>
        <span class="n">transition_probabilities_per_action</span><span class="p">,</span>
        <span class="n">next_state_fn</span><span class="p">,</span>
    <span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Generate the transition probability list of the grid.&quot;&quot;&quot;</span>
        <span class="n">transition_probability_list</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="n">none_in_next_states</span> <span class="o">=</span> <span class="kc">False</span>
        <span class="k">for</span> <span class="p">(</span>
            <span class="n">probability</span><span class="p">,</span>
            <span class="n">deterministic_action</span><span class="p">,</span>
        <span class="p">)</span> <span class="ow">in</span> <span class="n">transition_probabilities_per_action</span><span class="p">[</span><span class="n">action</span><span class="p">]:</span>
            <span class="n">next_state</span> <span class="o">=</span> <span class="n">next_state_fn</span><span class="p">(</span>
                <span class="n">state</span><span class="p">,</span>
                <span class="n">deterministic_action</span><span class="p">,</span>
                <span class="n">states</span><span class="p">,</span>
                <span class="n">output_none_if_non_existing_state</span><span class="o">=</span><span class="n">restrict_actions_to_available_states</span><span class="p">,</span>
            <span class="p">)</span>
            <span class="k">if</span> <span class="n">next_state</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
                <span class="n">none_in_next_states</span> <span class="o">=</span> <span class="kc">True</span>
                <span class="k">break</span>
            <span class="n">transition_probability_list</span><span class="o">.</span><span class="n">append</span><span class="p">((</span><span class="n">probability</span><span class="p">,</span> <span class="n">next_state</span><span class="p">))</span>

        <span class="k">if</span> <span class="ow">not</span> <span class="n">none_in_next_states</span><span class="p">:</span>
            <span class="k">return</span> <span class="n">transition_probability_list</span>

        <span class="k">return</span> <span class="p">[]</span>

    <span class="nd">@staticmethod</span>
    <span class="k">def</span> <span class="nf">_next_state_deterministic</span><span class="p">(</span>
        <span class="n">state</span><span class="p">,</span> <span class="n">action</span><span class="p">,</span> <span class="n">states</span><span class="p">,</span> <span class="n">output_none_if_non_existing_state</span><span class="o">=</span><span class="kc">False</span>
    <span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Output the next state given the action in a deterministic setting.</span>
<span class="sd">        Output None if next state not existing in case output_none_if_non_existing_state is True.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">next_state_candidate</span> <span class="o">=</span> <span class="nb">tuple</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">state</span><span class="p">)</span> <span class="o">+</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">action</span><span class="p">))</span>
        <span class="k">if</span> <span class="n">next_state_candidate</span> <span class="ow">in</span> <span class="n">states</span><span class="p">:</span>
            <span class="k">return</span> <span class="n">next_state_candidate</span>
        <span class="k">if</span> <span class="n">output_none_if_non_existing_state</span><span class="p">:</span>
            <span class="k">return</span> <span class="kc">None</span>
        <span class="k">return</span> <span class="n">state</span>
</code></pre></div></td></tr></table></div>
              </details>



  <div class="doc doc-children">









<div class="doc doc-object doc-function">


<h3 id="behavior_generation_lecture_python.mdp.mdp.GridMDP.__init__" class="doc doc-heading">
            <code class="highlight language-python"><span class="fm">__init__</span><span class="p">(</span><span class="n">grid</span><span class="p">,</span> <span class="n">initial_state</span><span class="p">,</span> <span class="n">terminal_states</span><span class="p">,</span> <span class="n">transition_probabilities_per_action</span><span class="p">,</span> <span class="n">restrict_actions_to_available_states</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span></code>

</h3>


    <div class="doc doc-contents ">

        <p>A Markov decision process on a grid.</p>


<p><span class="doc-section-title">Parameters:</span></p>
    <table>
      <thead>
        <tr>
          <th>Name</th>
          <th>Type</th>
          <th>Description</th>
          <th>Default</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                <code>grid</code>
            </td>
            <td>
                  <code><span title="typing.List">List</span>[<span title="typing.List">List</span>[<span title="typing.Union">Union</span>[float, None]]]</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>List of lists, containing the rewards of the grid
states or None.</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>initial_state</code>
            </td>
            <td>
                  <code><span title="behavior_generation_lecture_python.mdp.mdp.GridState">GridState</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Initial state in the grid.</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>terminal_states</code>
            </td>
            <td>
                  <code><span title="typing.Set">Set</span>[<span title="behavior_generation_lecture_python.mdp.mdp.GridState">GridState</span>]</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Set of terminal states in the grid.</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>transition_probabilities_per_action</code>
            </td>
            <td>
                  <code><span title="typing.Dict">Dict</span>[<span title="behavior_generation_lecture_python.mdp.mdp.GridState">GridState</span>, <span title="typing.List">List</span>[<span title="typing.Tuple">Tuple</span>[float, <span title="behavior_generation_lecture_python.mdp.mdp.GridState">GridState</span>]]]</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Dictionary of
transition probabilities per action, mapping from action
to list of tuples (probability, next state).</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>restrict_actions_to_available_states</code>
            </td>
            <td>
                  <code><span title="typing.Optional">Optional</span>[bool]</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Whether to restrict
actions to those that result in valid next states.</p>
              </div>
            </td>
            <td>
                  <code>False</code>
            </td>
          </tr>
      </tbody>
    </table>

            <details class="quote">
              <summary>Source code in <code>src/behavior_generation_lecture_python/mdp/mdp.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">174</span>
<span class="normal">175</span>
<span class="normal">176</span>
<span class="normal">177</span>
<span class="normal">178</span>
<span class="normal">179</span>
<span class="normal">180</span>
<span class="normal">181</span>
<span class="normal">182</span>
<span class="normal">183</span>
<span class="normal">184</span>
<span class="normal">185</span>
<span class="normal">186</span>
<span class="normal">187</span>
<span class="normal">188</span>
<span class="normal">189</span>
<span class="normal">190</span>
<span class="normal">191</span>
<span class="normal">192</span>
<span class="normal">193</span>
<span class="normal">194</span>
<span class="normal">195</span>
<span class="normal">196</span>
<span class="normal">197</span>
<span class="normal">198</span>
<span class="normal">199</span>
<span class="normal">200</span>
<span class="normal">201</span>
<span class="normal">202</span>
<span class="normal">203</span>
<span class="normal">204</span>
<span class="normal">205</span>
<span class="normal">206</span>
<span class="normal">207</span>
<span class="normal">208</span>
<span class="normal">209</span>
<span class="normal">210</span>
<span class="normal">211</span>
<span class="normal">212</span>
<span class="normal">213</span>
<span class="normal">214</span>
<span class="normal">215</span>
<span class="normal">216</span>
<span class="normal">217</span>
<span class="normal">218</span>
<span class="normal">219</span>
<span class="normal">220</span>
<span class="normal">221</span>
<span class="normal">222</span>
<span class="normal">223</span>
<span class="normal">224</span>
<span class="normal">225</span>
<span class="normal">226</span>
<span class="normal">227</span>
<span class="normal">228</span>
<span class="normal">229</span>
<span class="normal">230</span>
<span class="normal">231</span>
<span class="normal">232</span>
<span class="normal">233</span>
<span class="normal">234</span>
<span class="normal">235</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span>
    <span class="bp">self</span><span class="p">,</span>
    <span class="n">grid</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="n">List</span><span class="p">[</span><span class="n">Union</span><span class="p">[</span><span class="nb">float</span><span class="p">,</span> <span class="kc">None</span><span class="p">]]],</span>
    <span class="n">initial_state</span><span class="p">:</span> <span class="n">GridState</span><span class="p">,</span>
    <span class="n">terminal_states</span><span class="p">:</span> <span class="n">Set</span><span class="p">[</span><span class="n">GridState</span><span class="p">],</span>
    <span class="n">transition_probabilities_per_action</span><span class="p">:</span> <span class="n">Dict</span><span class="p">[</span>
        <span class="n">GridState</span><span class="p">,</span> <span class="n">List</span><span class="p">[</span><span class="n">Tuple</span><span class="p">[</span><span class="nb">float</span><span class="p">,</span> <span class="n">GridState</span><span class="p">]]</span>
    <span class="p">],</span>
    <span class="n">restrict_actions_to_available_states</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">bool</span><span class="p">]</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;A Markov decision process on a grid.</span>

<span class="sd">    Args:</span>
<span class="sd">        grid: List of lists, containing the rewards of the grid</span>
<span class="sd">            states or None.</span>
<span class="sd">        initial_state: Initial state in the grid.</span>
<span class="sd">        terminal_states: Set of terminal states in the grid.</span>
<span class="sd">        transition_probabilities_per_action: Dictionary of</span>
<span class="sd">            transition probabilities per action, mapping from action</span>
<span class="sd">            to list of tuples (probability, next state).</span>
<span class="sd">        restrict_actions_to_available_states: Whether to restrict</span>
<span class="sd">            actions to those that result in valid next states.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">states</span> <span class="o">=</span> <span class="nb">set</span><span class="p">()</span>
    <span class="n">reward</span> <span class="o">=</span> <span class="p">{}</span>
    <span class="n">grid</span> <span class="o">=</span> <span class="n">grid</span><span class="o">.</span><span class="n">copy</span><span class="p">()</span>
    <span class="n">grid</span><span class="o">.</span><span class="n">reverse</span><span class="p">()</span>  <span class="c1"># y-axis pointing upwards</span>
    <span class="n">rows</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">grid</span><span class="p">)</span>
    <span class="n">cols</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">grid</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">grid</span> <span class="o">=</span> <span class="n">grid</span>
    <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">cols</span><span class="p">):</span>
        <span class="k">for</span> <span class="n">y</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">rows</span><span class="p">):</span>
            <span class="k">if</span> <span class="n">grid</span><span class="p">[</span><span class="n">y</span><span class="p">][</span><span class="n">x</span><span class="p">]</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
                <span class="n">states</span><span class="o">.</span><span class="n">add</span><span class="p">((</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">))</span>
                <span class="n">reward_xy</span> <span class="o">=</span> <span class="n">grid</span><span class="p">[</span><span class="n">y</span><span class="p">][</span><span class="n">x</span><span class="p">]</span>
                <span class="k">assert</span> <span class="n">reward_xy</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span>
                <span class="n">reward</span><span class="p">[(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">)]</span> <span class="o">=</span> <span class="n">reward_xy</span>

    <span class="n">transition_probabilities</span> <span class="o">=</span> <span class="p">{}</span>
    <span class="k">for</span> <span class="n">state</span> <span class="ow">in</span> <span class="n">states</span><span class="p">:</span>
        <span class="k">for</span> <span class="n">action</span> <span class="ow">in</span> <span class="n">transition_probabilities_per_action</span><span class="o">.</span><span class="n">keys</span><span class="p">():</span>
            <span class="n">transition_probability_list</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_generate_transition_probability_list</span><span class="p">(</span>
                <span class="n">state</span><span class="o">=</span><span class="n">state</span><span class="p">,</span>
                <span class="n">action</span><span class="o">=</span><span class="n">action</span><span class="p">,</span>
                <span class="n">restrict_actions_to_available_states</span><span class="o">=</span><span class="n">restrict_actions_to_available_states</span><span class="p">,</span>
                <span class="n">states</span><span class="o">=</span><span class="n">states</span><span class="p">,</span>
                <span class="n">transition_probabilities_per_action</span><span class="o">=</span><span class="n">transition_probabilities_per_action</span><span class="p">,</span>
                <span class="n">next_state_fn</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">_next_state_deterministic</span><span class="p">,</span>
            <span class="p">)</span>
            <span class="k">if</span> <span class="n">transition_probability_list</span><span class="p">:</span>
                <span class="n">transition_probabilities</span><span class="p">[(</span><span class="n">state</span><span class="p">,</span> <span class="n">action</span><span class="p">)]</span> <span class="o">=</span> <span class="p">(</span>
                    <span class="n">transition_probability_list</span>
                <span class="p">)</span>

    <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span>
        <span class="n">states</span><span class="o">=</span><span class="n">states</span><span class="p">,</span>
        <span class="n">actions</span><span class="o">=</span><span class="nb">set</span><span class="p">(</span><span class="n">transition_probabilities_per_action</span><span class="o">.</span><span class="n">keys</span><span class="p">()),</span>
        <span class="n">initial_state</span><span class="o">=</span><span class="n">initial_state</span><span class="p">,</span>
        <span class="n">terminal_states</span><span class="o">=</span><span class="n">terminal_states</span><span class="p">,</span>
        <span class="n">transition_probabilities</span><span class="o">=</span><span class="n">transition_probabilities</span><span class="p">,</span>
        <span class="n">reward</span><span class="o">=</span><span class="n">reward</span><span class="p">,</span>
    <span class="p">)</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>



  </div>

    </div>

</div>

<div class="doc doc-object doc-class">



<h2 id="behavior_generation_lecture_python.mdp.mdp.MDP" class="doc doc-heading">
            <code>MDP</code>


</h2>


    <div class="doc doc-contents ">


        <p>A Markov decision process.</p>






              <details class="quote">
                <summary>Source code in <code>src/behavior_generation_lecture_python/mdp/mdp.py</code></summary>
                <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"> 63</span>
<span class="normal"> 64</span>
<span class="normal"> 65</span>
<span class="normal"> 66</span>
<span class="normal"> 67</span>
<span class="normal"> 68</span>
<span class="normal"> 69</span>
<span class="normal"> 70</span>
<span class="normal"> 71</span>
<span class="normal"> 72</span>
<span class="normal"> 73</span>
<span class="normal"> 74</span>
<span class="normal"> 75</span>
<span class="normal"> 76</span>
<span class="normal"> 77</span>
<span class="normal"> 78</span>
<span class="normal"> 79</span>
<span class="normal"> 80</span>
<span class="normal"> 81</span>
<span class="normal"> 82</span>
<span class="normal"> 83</span>
<span class="normal"> 84</span>
<span class="normal"> 85</span>
<span class="normal"> 86</span>
<span class="normal"> 87</span>
<span class="normal"> 88</span>
<span class="normal"> 89</span>
<span class="normal"> 90</span>
<span class="normal"> 91</span>
<span class="normal"> 92</span>
<span class="normal"> 93</span>
<span class="normal"> 94</span>
<span class="normal"> 95</span>
<span class="normal"> 96</span>
<span class="normal"> 97</span>
<span class="normal"> 98</span>
<span class="normal"> 99</span>
<span class="normal">100</span>
<span class="normal">101</span>
<span class="normal">102</span>
<span class="normal">103</span>
<span class="normal">104</span>
<span class="normal">105</span>
<span class="normal">106</span>
<span class="normal">107</span>
<span class="normal">108</span>
<span class="normal">109</span>
<span class="normal">110</span>
<span class="normal">111</span>
<span class="normal">112</span>
<span class="normal">113</span>
<span class="normal">114</span>
<span class="normal">115</span>
<span class="normal">116</span>
<span class="normal">117</span>
<span class="normal">118</span>
<span class="normal">119</span>
<span class="normal">120</span>
<span class="normal">121</span>
<span class="normal">122</span>
<span class="normal">123</span>
<span class="normal">124</span>
<span class="normal">125</span>
<span class="normal">126</span>
<span class="normal">127</span>
<span class="normal">128</span>
<span class="normal">129</span>
<span class="normal">130</span>
<span class="normal">131</span>
<span class="normal">132</span>
<span class="normal">133</span>
<span class="normal">134</span>
<span class="normal">135</span>
<span class="normal">136</span>
<span class="normal">137</span>
<span class="normal">138</span>
<span class="normal">139</span>
<span class="normal">140</span>
<span class="normal">141</span>
<span class="normal">142</span>
<span class="normal">143</span>
<span class="normal">144</span>
<span class="normal">145</span>
<span class="normal">146</span>
<span class="normal">147</span>
<span class="normal">148</span>
<span class="normal">149</span>
<span class="normal">150</span>
<span class="normal">151</span>
<span class="normal">152</span>
<span class="normal">153</span>
<span class="normal">154</span>
<span class="normal">155</span>
<span class="normal">156</span>
<span class="normal">157</span>
<span class="normal">158</span>
<span class="normal">159</span>
<span class="normal">160</span>
<span class="normal">161</span>
<span class="normal">162</span>
<span class="normal">163</span>
<span class="normal">164</span>
<span class="normal">165</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">class</span> <span class="nc">MDP</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;A Markov decision process.&quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">states</span><span class="p">:</span> <span class="n">Set</span><span class="p">[</span><span class="n">Any</span><span class="p">],</span>
        <span class="n">actions</span><span class="p">:</span> <span class="n">Set</span><span class="p">[</span><span class="n">Any</span><span class="p">],</span>
        <span class="n">initial_state</span><span class="p">:</span> <span class="n">Any</span><span class="p">,</span>
        <span class="n">terminal_states</span><span class="p">:</span> <span class="n">Set</span><span class="p">[</span><span class="n">Any</span><span class="p">],</span>
        <span class="n">transition_probabilities</span><span class="p">:</span> <span class="n">Dict</span><span class="p">[</span><span class="n">Tuple</span><span class="p">[</span><span class="n">Any</span><span class="p">,</span> <span class="n">Any</span><span class="p">],</span> <span class="n">List</span><span class="p">[</span><span class="n">Tuple</span><span class="p">[</span><span class="nb">float</span><span class="p">,</span> <span class="n">Any</span><span class="p">]]],</span>
        <span class="n">reward</span><span class="p">:</span> <span class="n">Dict</span><span class="p">[</span><span class="n">Any</span><span class="p">,</span> <span class="nb">float</span><span class="p">],</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;A Markov decision process.</span>

<span class="sd">        Args:</span>
<span class="sd">            states: Set of states.</span>
<span class="sd">            actions: Set of actions.</span>
<span class="sd">            initial_state: Initial state.</span>
<span class="sd">            terminal_states: Set of terminal states.</span>
<span class="sd">            transition_probabilities: Dictionary of transition</span>
<span class="sd">                probabilities, mapping from tuple (state, action) to</span>
<span class="sd">                list of tuples (probability, next state).</span>
<span class="sd">            reward: Dictionary of rewards per state, mapping from state</span>
<span class="sd">                to reward.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">states</span> <span class="o">=</span> <span class="n">states</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">actions</span> <span class="o">=</span> <span class="n">actions</span>

        <span class="k">assert</span> <span class="n">initial_state</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">states</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">initial_state</span> <span class="o">=</span> <span class="n">initial_state</span>

        <span class="k">for</span> <span class="n">terminal_state</span> <span class="ow">in</span> <span class="n">terminal_states</span><span class="p">:</span>
            <span class="k">assert</span> <span class="p">(</span>
                <span class="n">terminal_state</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">states</span>
            <span class="p">),</span> <span class="sa">f</span><span class="s2">&quot;The terminal state </span><span class="si">{</span><span class="n">terminal_state</span><span class="si">}</span><span class="s2"> is not in states </span><span class="si">{</span><span class="n">states</span><span class="si">}</span><span class="s2">&quot;</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">terminal_states</span> <span class="o">=</span> <span class="n">terminal_states</span>

        <span class="k">for</span> <span class="n">state</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">states</span><span class="p">:</span>
            <span class="k">for</span> <span class="n">action</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">actions</span><span class="p">:</span>
                <span class="k">if</span> <span class="p">(</span><span class="n">state</span><span class="p">,</span> <span class="n">action</span><span class="p">)</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">transition_probabilities</span><span class="p">:</span>
                    <span class="k">continue</span>
                <span class="n">total_prob</span> <span class="o">=</span> <span class="mf">0.0</span>
                <span class="k">for</span> <span class="n">prob</span><span class="p">,</span> <span class="n">next_state</span> <span class="ow">in</span> <span class="n">transition_probabilities</span><span class="p">[(</span><span class="n">state</span><span class="p">,</span> <span class="n">action</span><span class="p">)]:</span>
                    <span class="k">assert</span> <span class="p">(</span>
                        <span class="n">next_state</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">states</span>
                    <span class="p">),</span> <span class="sa">f</span><span class="s2">&quot;next_state=</span><span class="si">{</span><span class="n">next_state</span><span class="si">}</span><span class="s2"> is not in states=</span><span class="si">{</span><span class="n">states</span><span class="si">}</span><span class="s2">&quot;</span>
                    <span class="n">total_prob</span> <span class="o">+=</span> <span class="n">prob</span>
                <span class="k">assert</span> <span class="n">math</span><span class="o">.</span><span class="n">isclose</span><span class="p">(</span><span class="n">total_prob</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span> <span class="s2">&quot;Probabilities must add to one&quot;</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">transition_probabilities</span> <span class="o">=</span> <span class="n">transition_probabilities</span>

        <span class="k">assert</span> <span class="nb">set</span><span class="p">(</span><span class="n">reward</span><span class="o">.</span><span class="n">keys</span><span class="p">())</span> <span class="o">==</span> <span class="nb">set</span><span class="p">(</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">states</span>
        <span class="p">),</span> <span class="s2">&quot;Rewards must be defined for every state in the set of states&quot;</span>
        <span class="k">for</span> <span class="n">state</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">states</span><span class="p">:</span>
            <span class="k">assert</span> <span class="n">reward</span><span class="p">[</span><span class="n">state</span><span class="p">]</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">reward</span> <span class="o">=</span> <span class="n">reward</span>

    <span class="k">def</span> <span class="nf">get_states</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Set</span><span class="p">[</span><span class="n">Any</span><span class="p">]:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Get the set of states.&quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">states</span>

    <span class="k">def</span> <span class="nf">get_actions</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">state</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Set</span><span class="p">[</span><span class="n">Any</span><span class="p">]:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Get the set of actions available in a certain state, returns [None] for terminal states.&quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">is_terminal</span><span class="p">(</span><span class="n">state</span><span class="p">):</span>
            <span class="k">return</span> <span class="p">{</span><span class="kc">None</span><span class="p">}</span>
        <span class="k">return</span> <span class="p">{</span><span class="n">a</span> <span class="k">for</span> <span class="n">a</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">actions</span> <span class="k">if</span> <span class="p">(</span><span class="n">state</span><span class="p">,</span> <span class="n">a</span><span class="p">)</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">transition_probabilities</span><span class="p">}</span>

    <span class="k">def</span> <span class="nf">get_reward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">state</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">float</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Get the reward for a specific state.&quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">reward</span><span class="p">[</span><span class="n">state</span><span class="p">]</span>

    <span class="k">def</span> <span class="nf">is_terminal</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">state</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">bool</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Return whether a state is a terminal state.&quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="n">state</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">terminal_states</span>

    <span class="k">def</span> <span class="nf">get_transitions_with_probabilities</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span> <span class="n">state</span><span class="p">,</span> <span class="n">action</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">List</span><span class="p">[</span><span class="n">Tuple</span><span class="p">[</span><span class="nb">float</span><span class="p">,</span> <span class="n">Any</span><span class="p">]]:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Get the list of transitions with their probability, returns [(0.0, state)] for terminal states.&quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="n">action</span> <span class="ow">is</span> <span class="kc">None</span> <span class="ow">or</span> <span class="bp">self</span><span class="o">.</span><span class="n">is_terminal</span><span class="p">(</span><span class="n">state</span><span class="p">):</span>
            <span class="k">return</span> <span class="p">[(</span><span class="mf">0.0</span><span class="p">,</span> <span class="n">state</span><span class="p">)]</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">transition_probabilities</span><span class="p">[(</span><span class="n">state</span><span class="p">,</span> <span class="n">action</span><span class="p">)]</span>

    <span class="k">def</span> <span class="nf">sample_next_state</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">state</span><span class="p">,</span> <span class="n">action</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Any</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Randomly sample the next state given the current state and taken action.&quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">is_terminal</span><span class="p">(</span><span class="n">state</span><span class="p">):</span>
            <span class="k">return</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;No next state for terminal states.&quot;</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">action</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">return</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;Action must not be None.&quot;</span><span class="p">)</span>
        <span class="n">prob_per_transition</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">get_transitions_with_probabilities</span><span class="p">(</span><span class="n">state</span><span class="p">,</span> <span class="n">action</span><span class="p">)</span>
        <span class="n">num_actions</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">prob_per_transition</span><span class="p">)</span>
        <span class="n">choice</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">choice</span><span class="p">(</span>
            <span class="n">num_actions</span><span class="p">,</span> <span class="n">p</span><span class="o">=</span><span class="p">[</span><span class="n">ppa</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="k">for</span> <span class="n">ppa</span> <span class="ow">in</span> <span class="n">prob_per_transition</span><span class="p">]</span>
        <span class="p">)</span>
        <span class="k">return</span> <span class="n">prob_per_transition</span><span class="p">[</span><span class="n">choice</span><span class="p">][</span><span class="mi">1</span><span class="p">]</span>

    <span class="k">def</span> <span class="nf">execute_action</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">state</span><span class="p">,</span> <span class="n">action</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Tuple</span><span class="p">[</span><span class="n">Any</span><span class="p">,</span> <span class="nb">float</span><span class="p">,</span> <span class="nb">bool</span><span class="p">]:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Executes the action in the current state and returns the new state, obtained reward and terminal flag.&quot;&quot;&quot;</span>
        <span class="n">new_state</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">sample_next_state</span><span class="p">(</span><span class="n">state</span><span class="o">=</span><span class="n">state</span><span class="p">,</span> <span class="n">action</span><span class="o">=</span><span class="n">action</span><span class="p">)</span>
        <span class="n">reward</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">get_reward</span><span class="p">(</span><span class="n">state</span><span class="o">=</span><span class="n">new_state</span><span class="p">)</span>
        <span class="n">terminal</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">is_terminal</span><span class="p">(</span><span class="n">state</span><span class="o">=</span><span class="n">new_state</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">new_state</span><span class="p">,</span> <span class="n">reward</span><span class="p">,</span> <span class="n">terminal</span>
</code></pre></div></td></tr></table></div>
              </details>



  <div class="doc doc-children">









<div class="doc doc-object doc-function">


<h3 id="behavior_generation_lecture_python.mdp.mdp.MDP.__init__" class="doc doc-heading">
            <code class="highlight language-python"><span class="fm">__init__</span><span class="p">(</span><span class="n">states</span><span class="p">,</span> <span class="n">actions</span><span class="p">,</span> <span class="n">initial_state</span><span class="p">,</span> <span class="n">terminal_states</span><span class="p">,</span> <span class="n">transition_probabilities</span><span class="p">,</span> <span class="n">reward</span><span class="p">)</span></code>

</h3>


    <div class="doc doc-contents ">

        <p>A Markov decision process.</p>


<p><span class="doc-section-title">Parameters:</span></p>
    <table>
      <thead>
        <tr>
          <th>Name</th>
          <th>Type</th>
          <th>Description</th>
          <th>Default</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                <code>states</code>
            </td>
            <td>
                  <code><span title="typing.Set">Set</span>[<span title="typing.Any">Any</span>]</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Set of states.</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>actions</code>
            </td>
            <td>
                  <code><span title="typing.Set">Set</span>[<span title="typing.Any">Any</span>]</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Set of actions.</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>initial_state</code>
            </td>
            <td>
                  <code><span title="typing.Any">Any</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Initial state.</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>terminal_states</code>
            </td>
            <td>
                  <code><span title="typing.Set">Set</span>[<span title="typing.Any">Any</span>]</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Set of terminal states.</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>transition_probabilities</code>
            </td>
            <td>
                  <code><span title="typing.Dict">Dict</span>[<span title="typing.Tuple">Tuple</span>[<span title="typing.Any">Any</span>, <span title="typing.Any">Any</span>], <span title="typing.List">List</span>[<span title="typing.Tuple">Tuple</span>[float, <span title="typing.Any">Any</span>]]]</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Dictionary of transition
probabilities, mapping from tuple (state, action) to
list of tuples (probability, next state).</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>reward</code>
            </td>
            <td>
                  <code><span title="typing.Dict">Dict</span>[<span title="typing.Any">Any</span>, float]</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Dictionary of rewards per state, mapping from state
to reward.</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
      </tbody>
    </table>

            <details class="quote">
              <summary>Source code in <code>src/behavior_generation_lecture_python/mdp/mdp.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"> 66</span>
<span class="normal"> 67</span>
<span class="normal"> 68</span>
<span class="normal"> 69</span>
<span class="normal"> 70</span>
<span class="normal"> 71</span>
<span class="normal"> 72</span>
<span class="normal"> 73</span>
<span class="normal"> 74</span>
<span class="normal"> 75</span>
<span class="normal"> 76</span>
<span class="normal"> 77</span>
<span class="normal"> 78</span>
<span class="normal"> 79</span>
<span class="normal"> 80</span>
<span class="normal"> 81</span>
<span class="normal"> 82</span>
<span class="normal"> 83</span>
<span class="normal"> 84</span>
<span class="normal"> 85</span>
<span class="normal"> 86</span>
<span class="normal"> 87</span>
<span class="normal"> 88</span>
<span class="normal"> 89</span>
<span class="normal"> 90</span>
<span class="normal"> 91</span>
<span class="normal"> 92</span>
<span class="normal"> 93</span>
<span class="normal"> 94</span>
<span class="normal"> 95</span>
<span class="normal"> 96</span>
<span class="normal"> 97</span>
<span class="normal"> 98</span>
<span class="normal"> 99</span>
<span class="normal">100</span>
<span class="normal">101</span>
<span class="normal">102</span>
<span class="normal">103</span>
<span class="normal">104</span>
<span class="normal">105</span>
<span class="normal">106</span>
<span class="normal">107</span>
<span class="normal">108</span>
<span class="normal">109</span>
<span class="normal">110</span>
<span class="normal">111</span>
<span class="normal">112</span>
<span class="normal">113</span>
<span class="normal">114</span>
<span class="normal">115</span>
<span class="normal">116</span>
<span class="normal">117</span>
<span class="normal">118</span>
<span class="normal">119</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span>
    <span class="bp">self</span><span class="p">,</span>
    <span class="n">states</span><span class="p">:</span> <span class="n">Set</span><span class="p">[</span><span class="n">Any</span><span class="p">],</span>
    <span class="n">actions</span><span class="p">:</span> <span class="n">Set</span><span class="p">[</span><span class="n">Any</span><span class="p">],</span>
    <span class="n">initial_state</span><span class="p">:</span> <span class="n">Any</span><span class="p">,</span>
    <span class="n">terminal_states</span><span class="p">:</span> <span class="n">Set</span><span class="p">[</span><span class="n">Any</span><span class="p">],</span>
    <span class="n">transition_probabilities</span><span class="p">:</span> <span class="n">Dict</span><span class="p">[</span><span class="n">Tuple</span><span class="p">[</span><span class="n">Any</span><span class="p">,</span> <span class="n">Any</span><span class="p">],</span> <span class="n">List</span><span class="p">[</span><span class="n">Tuple</span><span class="p">[</span><span class="nb">float</span><span class="p">,</span> <span class="n">Any</span><span class="p">]]],</span>
    <span class="n">reward</span><span class="p">:</span> <span class="n">Dict</span><span class="p">[</span><span class="n">Any</span><span class="p">,</span> <span class="nb">float</span><span class="p">],</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;A Markov decision process.</span>

<span class="sd">    Args:</span>
<span class="sd">        states: Set of states.</span>
<span class="sd">        actions: Set of actions.</span>
<span class="sd">        initial_state: Initial state.</span>
<span class="sd">        terminal_states: Set of terminal states.</span>
<span class="sd">        transition_probabilities: Dictionary of transition</span>
<span class="sd">            probabilities, mapping from tuple (state, action) to</span>
<span class="sd">            list of tuples (probability, next state).</span>
<span class="sd">        reward: Dictionary of rewards per state, mapping from state</span>
<span class="sd">            to reward.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">states</span> <span class="o">=</span> <span class="n">states</span>

    <span class="bp">self</span><span class="o">.</span><span class="n">actions</span> <span class="o">=</span> <span class="n">actions</span>

    <span class="k">assert</span> <span class="n">initial_state</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">states</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">initial_state</span> <span class="o">=</span> <span class="n">initial_state</span>

    <span class="k">for</span> <span class="n">terminal_state</span> <span class="ow">in</span> <span class="n">terminal_states</span><span class="p">:</span>
        <span class="k">assert</span> <span class="p">(</span>
            <span class="n">terminal_state</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">states</span>
        <span class="p">),</span> <span class="sa">f</span><span class="s2">&quot;The terminal state </span><span class="si">{</span><span class="n">terminal_state</span><span class="si">}</span><span class="s2"> is not in states </span><span class="si">{</span><span class="n">states</span><span class="si">}</span><span class="s2">&quot;</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">terminal_states</span> <span class="o">=</span> <span class="n">terminal_states</span>

    <span class="k">for</span> <span class="n">state</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">states</span><span class="p">:</span>
        <span class="k">for</span> <span class="n">action</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">actions</span><span class="p">:</span>
            <span class="k">if</span> <span class="p">(</span><span class="n">state</span><span class="p">,</span> <span class="n">action</span><span class="p">)</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">transition_probabilities</span><span class="p">:</span>
                <span class="k">continue</span>
            <span class="n">total_prob</span> <span class="o">=</span> <span class="mf">0.0</span>
            <span class="k">for</span> <span class="n">prob</span><span class="p">,</span> <span class="n">next_state</span> <span class="ow">in</span> <span class="n">transition_probabilities</span><span class="p">[(</span><span class="n">state</span><span class="p">,</span> <span class="n">action</span><span class="p">)]:</span>
                <span class="k">assert</span> <span class="p">(</span>
                    <span class="n">next_state</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">states</span>
                <span class="p">),</span> <span class="sa">f</span><span class="s2">&quot;next_state=</span><span class="si">{</span><span class="n">next_state</span><span class="si">}</span><span class="s2"> is not in states=</span><span class="si">{</span><span class="n">states</span><span class="si">}</span><span class="s2">&quot;</span>
                <span class="n">total_prob</span> <span class="o">+=</span> <span class="n">prob</span>
            <span class="k">assert</span> <span class="n">math</span><span class="o">.</span><span class="n">isclose</span><span class="p">(</span><span class="n">total_prob</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span> <span class="s2">&quot;Probabilities must add to one&quot;</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">transition_probabilities</span> <span class="o">=</span> <span class="n">transition_probabilities</span>

    <span class="k">assert</span> <span class="nb">set</span><span class="p">(</span><span class="n">reward</span><span class="o">.</span><span class="n">keys</span><span class="p">())</span> <span class="o">==</span> <span class="nb">set</span><span class="p">(</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">states</span>
    <span class="p">),</span> <span class="s2">&quot;Rewards must be defined for every state in the set of states&quot;</span>
    <span class="k">for</span> <span class="n">state</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">states</span><span class="p">:</span>
        <span class="k">assert</span> <span class="n">reward</span><span class="p">[</span><span class="n">state</span><span class="p">]</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">reward</span> <span class="o">=</span> <span class="n">reward</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h3 id="behavior_generation_lecture_python.mdp.mdp.MDP.execute_action" class="doc doc-heading">
            <code class="highlight language-python"><span class="n">execute_action</span><span class="p">(</span><span class="n">state</span><span class="p">,</span> <span class="n">action</span><span class="p">)</span></code>

</h3>


    <div class="doc doc-contents ">

        <p>Executes the action in the current state and returns the new state, obtained reward and terminal flag.</p>

            <details class="quote">
              <summary>Source code in <code>src/behavior_generation_lecture_python/mdp/mdp.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">160</span>
<span class="normal">161</span>
<span class="normal">162</span>
<span class="normal">163</span>
<span class="normal">164</span>
<span class="normal">165</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span> <span class="nf">execute_action</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">state</span><span class="p">,</span> <span class="n">action</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Tuple</span><span class="p">[</span><span class="n">Any</span><span class="p">,</span> <span class="nb">float</span><span class="p">,</span> <span class="nb">bool</span><span class="p">]:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Executes the action in the current state and returns the new state, obtained reward and terminal flag.&quot;&quot;&quot;</span>
    <span class="n">new_state</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">sample_next_state</span><span class="p">(</span><span class="n">state</span><span class="o">=</span><span class="n">state</span><span class="p">,</span> <span class="n">action</span><span class="o">=</span><span class="n">action</span><span class="p">)</span>
    <span class="n">reward</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">get_reward</span><span class="p">(</span><span class="n">state</span><span class="o">=</span><span class="n">new_state</span><span class="p">)</span>
    <span class="n">terminal</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">is_terminal</span><span class="p">(</span><span class="n">state</span><span class="o">=</span><span class="n">new_state</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">new_state</span><span class="p">,</span> <span class="n">reward</span><span class="p">,</span> <span class="n">terminal</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h3 id="behavior_generation_lecture_python.mdp.mdp.MDP.get_actions" class="doc doc-heading">
            <code class="highlight language-python"><span class="n">get_actions</span><span class="p">(</span><span class="n">state</span><span class="p">)</span></code>

</h3>


    <div class="doc doc-contents ">

        <p>Get the set of actions available in a certain state, returns [None] for terminal states.</p>

            <details class="quote">
              <summary>Source code in <code>src/behavior_generation_lecture_python/mdp/mdp.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">125</span>
<span class="normal">126</span>
<span class="normal">127</span>
<span class="normal">128</span>
<span class="normal">129</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span> <span class="nf">get_actions</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">state</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Set</span><span class="p">[</span><span class="n">Any</span><span class="p">]:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Get the set of actions available in a certain state, returns [None] for terminal states.&quot;&quot;&quot;</span>
    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">is_terminal</span><span class="p">(</span><span class="n">state</span><span class="p">):</span>
        <span class="k">return</span> <span class="p">{</span><span class="kc">None</span><span class="p">}</span>
    <span class="k">return</span> <span class="p">{</span><span class="n">a</span> <span class="k">for</span> <span class="n">a</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">actions</span> <span class="k">if</span> <span class="p">(</span><span class="n">state</span><span class="p">,</span> <span class="n">a</span><span class="p">)</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">transition_probabilities</span><span class="p">}</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h3 id="behavior_generation_lecture_python.mdp.mdp.MDP.get_reward" class="doc doc-heading">
            <code class="highlight language-python"><span class="n">get_reward</span><span class="p">(</span><span class="n">state</span><span class="p">)</span></code>

</h3>


    <div class="doc doc-contents ">

        <p>Get the reward for a specific state.</p>

            <details class="quote">
              <summary>Source code in <code>src/behavior_generation_lecture_python/mdp/mdp.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">131</span>
<span class="normal">132</span>
<span class="normal">133</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span> <span class="nf">get_reward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">state</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">float</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Get the reward for a specific state.&quot;&quot;&quot;</span>
    <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">reward</span><span class="p">[</span><span class="n">state</span><span class="p">]</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h3 id="behavior_generation_lecture_python.mdp.mdp.MDP.get_states" class="doc doc-heading">
            <code class="highlight language-python"><span class="n">get_states</span><span class="p">()</span></code>

</h3>


    <div class="doc doc-contents ">

        <p>Get the set of states.</p>

            <details class="quote">
              <summary>Source code in <code>src/behavior_generation_lecture_python/mdp/mdp.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">121</span>
<span class="normal">122</span>
<span class="normal">123</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span> <span class="nf">get_states</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Set</span><span class="p">[</span><span class="n">Any</span><span class="p">]:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Get the set of states.&quot;&quot;&quot;</span>
    <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">states</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h3 id="behavior_generation_lecture_python.mdp.mdp.MDP.get_transitions_with_probabilities" class="doc doc-heading">
            <code class="highlight language-python"><span class="n">get_transitions_with_probabilities</span><span class="p">(</span><span class="n">state</span><span class="p">,</span> <span class="n">action</span><span class="p">)</span></code>

</h3>


    <div class="doc doc-contents ">

        <p>Get the list of transitions with their probability, returns [(0.0, state)] for terminal states.</p>

            <details class="quote">
              <summary>Source code in <code>src/behavior_generation_lecture_python/mdp/mdp.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">139</span>
<span class="normal">140</span>
<span class="normal">141</span>
<span class="normal">142</span>
<span class="normal">143</span>
<span class="normal">144</span>
<span class="normal">145</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span> <span class="nf">get_transitions_with_probabilities</span><span class="p">(</span>
    <span class="bp">self</span><span class="p">,</span> <span class="n">state</span><span class="p">,</span> <span class="n">action</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="n">List</span><span class="p">[</span><span class="n">Tuple</span><span class="p">[</span><span class="nb">float</span><span class="p">,</span> <span class="n">Any</span><span class="p">]]:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Get the list of transitions with their probability, returns [(0.0, state)] for terminal states.&quot;&quot;&quot;</span>
    <span class="k">if</span> <span class="n">action</span> <span class="ow">is</span> <span class="kc">None</span> <span class="ow">or</span> <span class="bp">self</span><span class="o">.</span><span class="n">is_terminal</span><span class="p">(</span><span class="n">state</span><span class="p">):</span>
        <span class="k">return</span> <span class="p">[(</span><span class="mf">0.0</span><span class="p">,</span> <span class="n">state</span><span class="p">)]</span>
    <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">transition_probabilities</span><span class="p">[(</span><span class="n">state</span><span class="p">,</span> <span class="n">action</span><span class="p">)]</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h3 id="behavior_generation_lecture_python.mdp.mdp.MDP.is_terminal" class="doc doc-heading">
            <code class="highlight language-python"><span class="n">is_terminal</span><span class="p">(</span><span class="n">state</span><span class="p">)</span></code>

</h3>


    <div class="doc doc-contents ">

        <p>Return whether a state is a terminal state.</p>

            <details class="quote">
              <summary>Source code in <code>src/behavior_generation_lecture_python/mdp/mdp.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">135</span>
<span class="normal">136</span>
<span class="normal">137</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span> <span class="nf">is_terminal</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">state</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">bool</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Return whether a state is a terminal state.&quot;&quot;&quot;</span>
    <span class="k">return</span> <span class="n">state</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">terminal_states</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h3 id="behavior_generation_lecture_python.mdp.mdp.MDP.sample_next_state" class="doc doc-heading">
            <code class="highlight language-python"><span class="n">sample_next_state</span><span class="p">(</span><span class="n">state</span><span class="p">,</span> <span class="n">action</span><span class="p">)</span></code>

</h3>


    <div class="doc doc-contents ">

        <p>Randomly sample the next state given the current state and taken action.</p>

            <details class="quote">
              <summary>Source code in <code>src/behavior_generation_lecture_python/mdp/mdp.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">147</span>
<span class="normal">148</span>
<span class="normal">149</span>
<span class="normal">150</span>
<span class="normal">151</span>
<span class="normal">152</span>
<span class="normal">153</span>
<span class="normal">154</span>
<span class="normal">155</span>
<span class="normal">156</span>
<span class="normal">157</span>
<span class="normal">158</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span> <span class="nf">sample_next_state</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">state</span><span class="p">,</span> <span class="n">action</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Any</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Randomly sample the next state given the current state and taken action.&quot;&quot;&quot;</span>
    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">is_terminal</span><span class="p">(</span><span class="n">state</span><span class="p">):</span>
        <span class="k">return</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;No next state for terminal states.&quot;</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">action</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="k">return</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;Action must not be None.&quot;</span><span class="p">)</span>
    <span class="n">prob_per_transition</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">get_transitions_with_probabilities</span><span class="p">(</span><span class="n">state</span><span class="p">,</span> <span class="n">action</span><span class="p">)</span>
    <span class="n">num_actions</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">prob_per_transition</span><span class="p">)</span>
    <span class="n">choice</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">choice</span><span class="p">(</span>
        <span class="n">num_actions</span><span class="p">,</span> <span class="n">p</span><span class="o">=</span><span class="p">[</span><span class="n">ppa</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="k">for</span> <span class="n">ppa</span> <span class="ow">in</span> <span class="n">prob_per_transition</span><span class="p">]</span>
    <span class="p">)</span>
    <span class="k">return</span> <span class="n">prob_per_transition</span><span class="p">[</span><span class="n">choice</span><span class="p">][</span><span class="mi">1</span><span class="p">]</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>



  </div>

    </div>

</div>

<div class="doc doc-object doc-class">



<h2 id="behavior_generation_lecture_python.mdp.mdp.PolicyGradientBuffer" class="doc doc-heading">
            <code>PolicyGradientBuffer</code>


  <span class="doc doc-labels">
      <small class="doc doc-label doc-label-dataclass"><code>dataclass</code></small>
  </span>

</h2>


    <div class="doc doc-contents ">


        <p>Buffer for the policy gradient method.</p>






              <details class="quote">
                <summary>Source code in <code>src/behavior_generation_lecture_python/mdp/mdp.py</code></summary>
                <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">509</span>
<span class="normal">510</span>
<span class="normal">511</span>
<span class="normal">512</span>
<span class="normal">513</span>
<span class="normal">514</span>
<span class="normal">515</span>
<span class="normal">516</span>
<span class="normal">517</span>
<span class="normal">518</span>
<span class="normal">519</span>
<span class="normal">520</span>
<span class="normal">521</span>
<span class="normal">522</span>
<span class="normal">523</span>
<span class="normal">524</span>
<span class="normal">525</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="nd">@dataclass</span>
<span class="k">class</span> <span class="nc">PolicyGradientBuffer</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Buffer for the policy gradient method.&quot;&quot;&quot;</span>

    <span class="n">states</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="n">Any</span><span class="p">]</span> <span class="o">=</span> <span class="n">field</span><span class="p">(</span><span class="n">default_factory</span><span class="o">=</span><span class="nb">list</span><span class="p">)</span>
    <span class="n">actions</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="n">Any</span><span class="p">]</span> <span class="o">=</span> <span class="n">field</span><span class="p">(</span><span class="n">default_factory</span><span class="o">=</span><span class="nb">list</span><span class="p">)</span>
    <span class="n">weights</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="nb">float</span><span class="p">]</span> <span class="o">=</span> <span class="n">field</span><span class="p">(</span><span class="n">default_factory</span><span class="o">=</span><span class="nb">list</span><span class="p">)</span>
    <span class="n">episode_returns</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="nb">float</span><span class="p">]</span> <span class="o">=</span> <span class="n">field</span><span class="p">(</span><span class="n">default_factory</span><span class="o">=</span><span class="nb">list</span><span class="p">)</span>
    <span class="n">episode_lengths</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="nb">int</span><span class="p">]</span> <span class="o">=</span> <span class="n">field</span><span class="p">(</span><span class="n">default_factory</span><span class="o">=</span><span class="nb">list</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">mean_episode_return</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">float</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Mean episode return.&quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="nb">float</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">episode_returns</span><span class="p">))</span>

    <span class="k">def</span> <span class="nf">mean_episode_length</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">float</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Mean episode length.&quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="nb">float</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">episode_lengths</span><span class="p">))</span>
</code></pre></div></td></tr></table></div>
              </details>



  <div class="doc doc-children">









<div class="doc doc-object doc-function">


<h3 id="behavior_generation_lecture_python.mdp.mdp.PolicyGradientBuffer.mean_episode_length" class="doc doc-heading">
            <code class="highlight language-python"><span class="n">mean_episode_length</span><span class="p">()</span></code>

</h3>


    <div class="doc doc-contents ">

        <p>Mean episode length.</p>

            <details class="quote">
              <summary>Source code in <code>src/behavior_generation_lecture_python/mdp/mdp.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">523</span>
<span class="normal">524</span>
<span class="normal">525</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span> <span class="nf">mean_episode_length</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">float</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Mean episode length.&quot;&quot;&quot;</span>
    <span class="k">return</span> <span class="nb">float</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">episode_lengths</span><span class="p">))</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h3 id="behavior_generation_lecture_python.mdp.mdp.PolicyGradientBuffer.mean_episode_return" class="doc doc-heading">
            <code class="highlight language-python"><span class="n">mean_episode_return</span><span class="p">()</span></code>

</h3>


    <div class="doc doc-contents ">

        <p>Mean episode return.</p>

            <details class="quote">
              <summary>Source code in <code>src/behavior_generation_lecture_python/mdp/mdp.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">519</span>
<span class="normal">520</span>
<span class="normal">521</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span> <span class="nf">mean_episode_return</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">float</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Mean episode return.&quot;&quot;&quot;</span>
    <span class="k">return</span> <span class="nb">float</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">episode_returns</span><span class="p">))</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>



  </div>

    </div>

</div>


<div class="doc doc-object doc-function">


<h2 id="behavior_generation_lecture_python.mdp.mdp.best_action_from_q_table" class="doc doc-heading">
            <code class="highlight language-python"><span class="n">best_action_from_q_table</span><span class="p">(</span><span class="o">*</span><span class="p">,</span> <span class="n">state</span><span class="p">,</span> <span class="n">available_actions</span><span class="p">,</span> <span class="n">q_table</span><span class="p">)</span></code>

</h2>


    <div class="doc doc-contents ">

        <p>Derive the best action from a Q table.</p>


<p><span class="doc-section-title">Parameters:</span></p>
    <table>
      <thead>
        <tr>
          <th>Name</th>
          <th>Type</th>
          <th>Description</th>
          <th>Default</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                <code>state</code>
            </td>
            <td>
                  <code><span title="typing.Any">Any</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>The state in which to take an action.</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>available_actions</code>
            </td>
            <td>
                  <code><span title="typing.Set">Set</span>[<span title="typing.Any">Any</span>]</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Set of available actions.</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>q_table</code>
            </td>
            <td>
                  <code><span title="behavior_generation_lecture_python.mdp.mdp.QTable">QTable</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>The Q table, mapping from state-action pair to value estimate.</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
      </tbody>
    </table>


    <p><span class="doc-section-title">Returns:</span></p>
    <table>
      <thead>
        <tr>
          <th>Type</th>
          <th>Description</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                  <code><span title="typing.Any">Any</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>The best action according to the Q table.</p>
              </div>
            </td>
          </tr>
      </tbody>
    </table>

            <details class="quote">
              <summary>Source code in <code>src/behavior_generation_lecture_python/mdp/mdp.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">378</span>
<span class="normal">379</span>
<span class="normal">380</span>
<span class="normal">381</span>
<span class="normal">382</span>
<span class="normal">383</span>
<span class="normal">384</span>
<span class="normal">385</span>
<span class="normal">386</span>
<span class="normal">387</span>
<span class="normal">388</span>
<span class="normal">389</span>
<span class="normal">390</span>
<span class="normal">391</span>
<span class="normal">392</span>
<span class="normal">393</span>
<span class="normal">394</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span> <span class="nf">best_action_from_q_table</span><span class="p">(</span>
    <span class="o">*</span><span class="p">,</span> <span class="n">state</span><span class="p">:</span> <span class="n">Any</span><span class="p">,</span> <span class="n">available_actions</span><span class="p">:</span> <span class="n">Set</span><span class="p">[</span><span class="n">Any</span><span class="p">],</span> <span class="n">q_table</span><span class="p">:</span> <span class="n">QTable</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Any</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Derive the best action from a Q table.</span>

<span class="sd">    Args:</span>
<span class="sd">        state: The state in which to take an action.</span>
<span class="sd">        available_actions: Set of available actions.</span>
<span class="sd">        q_table: The Q table, mapping from state-action pair to value estimate.</span>

<span class="sd">    Returns:</span>
<span class="sd">        The best action according to the Q table.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">available_actions_list</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="n">available_actions</span><span class="p">)</span>
    <span class="n">values</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="n">q_table</span><span class="p">[(</span><span class="n">state</span><span class="p">,</span> <span class="n">action</span><span class="p">)]</span> <span class="k">for</span> <span class="n">action</span> <span class="ow">in</span> <span class="n">available_actions_list</span><span class="p">])</span>
    <span class="n">action</span> <span class="o">=</span> <span class="n">available_actions_list</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">values</span><span class="p">)]</span>
    <span class="k">return</span> <span class="n">action</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h2 id="behavior_generation_lecture_python.mdp.mdp.derive_deterministic_policy" class="doc doc-heading">
            <code class="highlight language-python"><span class="n">derive_deterministic_policy</span><span class="p">(</span><span class="n">mdp</span><span class="p">,</span> <span class="n">policy</span><span class="p">)</span></code>

</h2>


    <div class="doc doc-contents ">

        <p>Compute the best policy for an MDP given the stochastic policy.</p>


<p><span class="doc-section-title">Parameters:</span></p>
    <table>
      <thead>
        <tr>
          <th>Name</th>
          <th>Type</th>
          <th>Description</th>
          <th>Default</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                <code>mdp</code>
            </td>
            <td>
                  <code><a class="autorefs autorefs-internal" title="behavior_generation_lecture_python.mdp.mdp.MDP" href="#behavior_generation_lecture_python.mdp.mdp.MDP">MDP</a></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>The underlying MDP.</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>policy</code>
            </td>
            <td>
                  <code><a class="autorefs autorefs-internal" title="behavior_generation_lecture_python.mdp.policy.CategorialPolicy" href="../policy/#behavior_generation_lecture_python.mdp.policy.CategorialPolicy">CategorialPolicy</a></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>The stochastic policy.</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
      </tbody>
    </table>


    <p><span class="doc-section-title">Returns:</span></p>
    <table>
      <thead>
        <tr>
          <th>Type</th>
          <th>Description</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                  <code><span title="typing.Dict">Dict</span>[<span title="typing.Any">Any</span>, <span title="typing.Any">Any</span>]</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Deterministic policy, i.e. mapping from state to action.</p>
              </div>
            </td>
          </tr>
      </tbody>
    </table>

            <details class="quote">
              <summary>Source code in <code>src/behavior_generation_lecture_python/mdp/mdp.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">653</span>
<span class="normal">654</span>
<span class="normal">655</span>
<span class="normal">656</span>
<span class="normal">657</span>
<span class="normal">658</span>
<span class="normal">659</span>
<span class="normal">660</span>
<span class="normal">661</span>
<span class="normal">662</span>
<span class="normal">663</span>
<span class="normal">664</span>
<span class="normal">665</span>
<span class="normal">666</span>
<span class="normal">667</span>
<span class="normal">668</span>
<span class="normal">669</span>
<span class="normal">670</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span> <span class="nf">derive_deterministic_policy</span><span class="p">(</span><span class="n">mdp</span><span class="p">:</span> <span class="n">MDP</span><span class="p">,</span> <span class="n">policy</span><span class="p">:</span> <span class="n">CategorialPolicy</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Dict</span><span class="p">[</span><span class="n">Any</span><span class="p">,</span> <span class="n">Any</span><span class="p">]:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Compute the best policy for an MDP given the stochastic policy.</span>

<span class="sd">    Args:</span>
<span class="sd">        mdp: The underlying MDP.</span>
<span class="sd">        policy: The stochastic policy.</span>

<span class="sd">    Returns:</span>
<span class="sd">        Deterministic policy, i.e. mapping from state to action.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">pi</span> <span class="o">=</span> <span class="p">{}</span>
    <span class="k">for</span> <span class="n">state</span> <span class="ow">in</span> <span class="n">mdp</span><span class="o">.</span><span class="n">get_states</span><span class="p">():</span>
        <span class="k">if</span> <span class="n">mdp</span><span class="o">.</span><span class="n">is_terminal</span><span class="p">(</span><span class="n">state</span><span class="p">):</span>
            <span class="k">continue</span>
        <span class="n">pi</span><span class="p">[</span><span class="n">state</span><span class="p">]</span> <span class="o">=</span> <span class="n">policy</span><span class="o">.</span><span class="n">get_action</span><span class="p">(</span>
            <span class="n">state</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">as_tensor</span><span class="p">(</span><span class="n">state</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">float32</span><span class="p">),</span> <span class="n">deterministic</span><span class="o">=</span><span class="kc">True</span>
        <span class="p">)</span>
    <span class="k">return</span> <span class="n">pi</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h2 id="behavior_generation_lecture_python.mdp.mdp.derive_policy" class="doc doc-heading">
            <code class="highlight language-python"><span class="n">derive_policy</span><span class="p">(</span><span class="n">mdp</span><span class="p">,</span> <span class="n">utility_of_states</span><span class="p">)</span></code>

</h2>


    <div class="doc doc-contents ">

        <p>Compute the best policy for an MDP given the utility of the states.</p>


<p><span class="doc-section-title">Parameters:</span></p>
    <table>
      <thead>
        <tr>
          <th>Name</th>
          <th>Type</th>
          <th>Description</th>
          <th>Default</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                <code>mdp</code>
            </td>
            <td>
                  <code><a class="autorefs autorefs-internal" title="behavior_generation_lecture_python.mdp.mdp.MDP" href="#behavior_generation_lecture_python.mdp.mdp.MDP">MDP</a></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>The underlying MDP.</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>utility_of_states</code>
            </td>
            <td>
                  <code><span title="behavior_generation_lecture_python.mdp.mdp.StateValueTable">StateValueTable</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>The dictionary containing the utility
(estimate) of all states.</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
      </tbody>
    </table>


    <p><span class="doc-section-title">Returns:</span></p>
    <table>
      <thead>
        <tr>
          <th>Type</th>
          <th>Description</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                  <code><span title="typing.Dict">Dict</span>[<span title="typing.Any">Any</span>, <span title="typing.Any">Any</span>]</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Policy, i.e. mapping from state to action.</p>
              </div>
            </td>
          </tr>
      </tbody>
    </table>

            <details class="quote">
              <summary>Source code in <code>src/behavior_generation_lecture_python/mdp/mdp.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">310</span>
<span class="normal">311</span>
<span class="normal">312</span>
<span class="normal">313</span>
<span class="normal">314</span>
<span class="normal">315</span>
<span class="normal">316</span>
<span class="normal">317</span>
<span class="normal">318</span>
<span class="normal">319</span>
<span class="normal">320</span>
<span class="normal">321</span>
<span class="normal">322</span>
<span class="normal">323</span>
<span class="normal">324</span>
<span class="normal">325</span>
<span class="normal">326</span>
<span class="normal">327</span>
<span class="normal">328</span>
<span class="normal">329</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span> <span class="nf">derive_policy</span><span class="p">(</span><span class="n">mdp</span><span class="p">:</span> <span class="n">MDP</span><span class="p">,</span> <span class="n">utility_of_states</span><span class="p">:</span> <span class="n">StateValueTable</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Dict</span><span class="p">[</span><span class="n">Any</span><span class="p">,</span> <span class="n">Any</span><span class="p">]:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Compute the best policy for an MDP given the utility of the states.</span>

<span class="sd">    Args:</span>
<span class="sd">        mdp: The underlying MDP.</span>
<span class="sd">        utility_of_states: The dictionary containing the utility</span>
<span class="sd">            (estimate) of all states.</span>

<span class="sd">    Returns:</span>
<span class="sd">        Policy, i.e. mapping from state to action.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">pi</span> <span class="o">=</span> <span class="p">{}</span>
    <span class="k">for</span> <span class="n">state</span> <span class="ow">in</span> <span class="n">mdp</span><span class="o">.</span><span class="n">get_states</span><span class="p">():</span>
        <span class="n">pi</span><span class="p">[</span><span class="n">state</span><span class="p">]</span> <span class="o">=</span> <span class="nb">max</span><span class="p">(</span>
            <span class="n">mdp</span><span class="o">.</span><span class="n">get_actions</span><span class="p">(</span><span class="n">state</span><span class="p">),</span>
            <span class="n">key</span><span class="o">=</span><span class="k">lambda</span> <span class="n">action</span><span class="p">:</span> <span class="n">expected_utility_of_action</span><span class="p">(</span>
                <span class="n">mdp</span><span class="o">=</span><span class="n">mdp</span><span class="p">,</span> <span class="n">state</span><span class="o">=</span><span class="n">state</span><span class="p">,</span> <span class="n">action</span><span class="o">=</span><span class="n">action</span><span class="p">,</span> <span class="n">utility_of_states</span><span class="o">=</span><span class="n">utility_of_states</span>
            <span class="p">),</span>
        <span class="p">)</span>
    <span class="k">return</span> <span class="n">pi</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h2 id="behavior_generation_lecture_python.mdp.mdp.expected_utility_of_action" class="doc doc-heading">
            <code class="highlight language-python"><span class="n">expected_utility_of_action</span><span class="p">(</span><span class="n">mdp</span><span class="p">,</span> <span class="n">state</span><span class="p">,</span> <span class="n">action</span><span class="p">,</span> <span class="n">utility_of_states</span><span class="p">)</span></code>

</h2>


    <div class="doc doc-contents ">

        <p>Compute the expected utility of taking an action in a state.</p>


<p><span class="doc-section-title">Parameters:</span></p>
    <table>
      <thead>
        <tr>
          <th>Name</th>
          <th>Type</th>
          <th>Description</th>
          <th>Default</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                <code>mdp</code>
            </td>
            <td>
                  <code><a class="autorefs autorefs-internal" title="behavior_generation_lecture_python.mdp.mdp.MDP" href="#behavior_generation_lecture_python.mdp.mdp.MDP">MDP</a></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>The underlying MDP.</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>state</code>
            </td>
            <td>
                  <code><span title="typing.Any">Any</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>The start state.</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>action</code>
            </td>
            <td>
                  <code><span title="typing.Any">Any</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>The action to be taken.</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>utility_of_states</code>
            </td>
            <td>
                  <code><span title="behavior_generation_lecture_python.mdp.mdp.StateValueTable">StateValueTable</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>The dictionary containing the utility
(estimate) of all states.</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
      </tbody>
    </table>


    <p><span class="doc-section-title">Returns:</span></p>
    <table>
      <thead>
        <tr>
          <th>Type</th>
          <th>Description</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                  <code>float</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Expected utility</p>
              </div>
            </td>
          </tr>
      </tbody>
    </table>

            <details class="quote">
              <summary>Source code in <code>src/behavior_generation_lecture_python/mdp/mdp.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">287</span>
<span class="normal">288</span>
<span class="normal">289</span>
<span class="normal">290</span>
<span class="normal">291</span>
<span class="normal">292</span>
<span class="normal">293</span>
<span class="normal">294</span>
<span class="normal">295</span>
<span class="normal">296</span>
<span class="normal">297</span>
<span class="normal">298</span>
<span class="normal">299</span>
<span class="normal">300</span>
<span class="normal">301</span>
<span class="normal">302</span>
<span class="normal">303</span>
<span class="normal">304</span>
<span class="normal">305</span>
<span class="normal">306</span>
<span class="normal">307</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span> <span class="nf">expected_utility_of_action</span><span class="p">(</span>
    <span class="n">mdp</span><span class="p">:</span> <span class="n">MDP</span><span class="p">,</span> <span class="n">state</span><span class="p">:</span> <span class="n">Any</span><span class="p">,</span> <span class="n">action</span><span class="p">:</span> <span class="n">Any</span><span class="p">,</span> <span class="n">utility_of_states</span><span class="p">:</span> <span class="n">StateValueTable</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">float</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Compute the expected utility of taking an action in a state.</span>

<span class="sd">    Args:</span>
<span class="sd">        mdp: The underlying MDP.</span>
<span class="sd">        state: The start state.</span>
<span class="sd">        action: The action to be taken.</span>
<span class="sd">        utility_of_states: The dictionary containing the utility</span>
<span class="sd">            (estimate) of all states.</span>

<span class="sd">    Returns:</span>
<span class="sd">        Expected utility</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">return</span> <span class="nb">sum</span><span class="p">(</span>
        <span class="n">p</span> <span class="o">*</span> <span class="p">(</span><span class="n">mdp</span><span class="o">.</span><span class="n">get_reward</span><span class="p">(</span><span class="n">next_state</span><span class="p">)</span> <span class="o">+</span> <span class="n">utility_of_states</span><span class="p">[</span><span class="n">next_state</span><span class="p">])</span>
        <span class="k">for</span> <span class="p">(</span><span class="n">p</span><span class="p">,</span> <span class="n">next_state</span><span class="p">)</span> <span class="ow">in</span> <span class="n">mdp</span><span class="o">.</span><span class="n">get_transitions_with_probabilities</span><span class="p">(</span>
            <span class="n">state</span><span class="o">=</span><span class="n">state</span><span class="p">,</span> <span class="n">action</span><span class="o">=</span><span class="n">action</span>
        <span class="p">)</span>
    <span class="p">)</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h2 id="behavior_generation_lecture_python.mdp.mdp.greedy_value_estimate_for_state" class="doc doc-heading">
            <code class="highlight language-python"><span class="n">greedy_value_estimate_for_state</span><span class="p">(</span><span class="o">*</span><span class="p">,</span> <span class="n">q_table</span><span class="p">,</span> <span class="n">state</span><span class="p">)</span></code>

</h2>


    <div class="doc doc-contents ">

        <p>Compute the greedy (best possible) value estimate for a state from the Q table.</p>


<p><span class="doc-section-title">Parameters:</span></p>
    <table>
      <thead>
        <tr>
          <th>Name</th>
          <th>Type</th>
          <th>Description</th>
          <th>Default</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                <code>state</code>
            </td>
            <td>
                  <code><span title="typing.Any">Any</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>The state for which to estimate the value, when being greedy.</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>q_table</code>
            </td>
            <td>
                  <code><span title="behavior_generation_lecture_python.mdp.mdp.QTable">QTable</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>The Q table, mapping from state-action pair to value estimate.</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
      </tbody>
    </table>


    <p><span class="doc-section-title">Returns:</span></p>
    <table>
      <thead>
        <tr>
          <th>Type</th>
          <th>Description</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                  <code>float</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>The value based on the greedy estimate.</p>
              </div>
            </td>
          </tr>
      </tbody>
    </table>

            <details class="quote">
              <summary>Source code in <code>src/behavior_generation_lecture_python/mdp/mdp.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">412</span>
<span class="normal">413</span>
<span class="normal">414</span>
<span class="normal">415</span>
<span class="normal">416</span>
<span class="normal">417</span>
<span class="normal">418</span>
<span class="normal">419</span>
<span class="normal">420</span>
<span class="normal">421</span>
<span class="normal">422</span>
<span class="normal">423</span>
<span class="normal">424</span>
<span class="normal">425</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span> <span class="nf">greedy_value_estimate_for_state</span><span class="p">(</span><span class="o">*</span><span class="p">,</span> <span class="n">q_table</span><span class="p">:</span> <span class="n">QTable</span><span class="p">,</span> <span class="n">state</span><span class="p">:</span> <span class="n">Any</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">float</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Compute the greedy (best possible) value estimate for a state from the Q table.</span>

<span class="sd">    Args:</span>
<span class="sd">        state: The state for which to estimate the value, when being greedy.</span>
<span class="sd">        q_table: The Q table, mapping from state-action pair to value estimate.</span>

<span class="sd">    Returns:</span>
<span class="sd">        The value based on the greedy estimate.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">available_actions</span> <span class="o">=</span> <span class="p">[</span>
        <span class="n">state_action</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="k">for</span> <span class="n">state_action</span> <span class="ow">in</span> <span class="n">q_table</span><span class="o">.</span><span class="n">keys</span><span class="p">()</span> <span class="k">if</span> <span class="n">state_action</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">==</span> <span class="n">state</span>
    <span class="p">]</span>
    <span class="k">return</span> <span class="nb">max</span><span class="p">(</span><span class="n">q_table</span><span class="p">[</span><span class="n">state</span><span class="p">,</span> <span class="n">action</span><span class="p">]</span> <span class="k">for</span> <span class="n">action</span> <span class="ow">in</span> <span class="n">available_actions</span><span class="p">)</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h2 id="behavior_generation_lecture_python.mdp.mdp.policy_gradient" class="doc doc-heading">
            <code class="highlight language-python"><span class="n">policy_gradient</span><span class="p">(</span><span class="o">*</span><span class="p">,</span> <span class="n">mdp</span><span class="p">,</span> <span class="n">policy</span><span class="p">,</span> <span class="n">lr</span><span class="o">=</span><span class="mf">0.01</span><span class="p">,</span> <span class="n">iterations</span><span class="o">=</span><span class="mi">50</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="mi">5000</span><span class="p">,</span> <span class="n">return_history</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">use_random_init_state</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">verbose</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span></code>

</h2>


    <div class="doc doc-contents ">

        <p>Train a paramterized policy using vanilla policy gradient.</p>
<p>Adapted from: https://github.com/openai/spinningup/blob/master/spinup/examples/pytorch/pg_math/1_simple_pg.py</p>
<p>The MIT License (MIT)</p>
<p>Copyright (c) 2018 OpenAI (http://openai.com)</p>
<p>Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the "Software"), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions:</p>
<p>The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software.</p>
<p>THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.</p>


<p><span class="doc-section-title">Parameters:</span></p>
    <table>
      <thead>
        <tr>
          <th>Name</th>
          <th>Type</th>
          <th>Description</th>
          <th>Default</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                <code>mdp</code>
            </td>
            <td>
                  <code><a class="autorefs autorefs-internal" title="behavior_generation_lecture_python.mdp.mdp.MDP" href="#behavior_generation_lecture_python.mdp.mdp.MDP">MDP</a></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>The underlying MDP.</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>policy</code>
            </td>
            <td>
                  <code><a class="autorefs autorefs-internal" title="behavior_generation_lecture_python.mdp.policy.CategorialPolicy" href="../policy/#behavior_generation_lecture_python.mdp.policy.CategorialPolicy">CategorialPolicy</a></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>The stochastic policy to be trained.</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>lr</code>
            </td>
            <td>
                  <code>float</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Learning rate.</p>
              </div>
            </td>
            <td>
                  <code>0.01</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>iterations</code>
            </td>
            <td>
                  <code>int</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Number of iterations.</p>
              </div>
            </td>
            <td>
                  <code>50</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>batch_size</code>
            </td>
            <td>
                  <code>int</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Number of samples generated for each policy update.</p>
              </div>
            </td>
            <td>
                  <code>5000</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>return_history</code>
            </td>
            <td>
                  <code>bool</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Whether to return the whole history of value estimates
instead of just the final estimate.</p>
              </div>
            </td>
            <td>
                  <code>False</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>use_random_init_state</code>
            </td>
            <td>
                  <code>bool</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>bool, if the agent should be initialized randomly.</p>
              </div>
            </td>
            <td>
                  <code>False</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>verbose</code>
            </td>
            <td>
                  <code>bool</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>bool, if traing progress should be printed.</p>
              </div>
            </td>
            <td>
                  <code>True</code>
            </td>
          </tr>
      </tbody>
    </table>


    <p><span class="doc-section-title">Returns:</span></p>
    <table>
      <thead>
        <tr>
          <th>Type</th>
          <th>Description</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                  <code><span title="typing.Union">Union</span>[<span title="typing.List">List</span>[<a class="autorefs autorefs-internal" title="behavior_generation_lecture_python.mdp.policy.CategorialPolicy" href="../policy/#behavior_generation_lecture_python.mdp.policy.CategorialPolicy">CategorialPolicy</a>], <a class="autorefs autorefs-internal" title="behavior_generation_lecture_python.mdp.policy.CategorialPolicy" href="../policy/#behavior_generation_lecture_python.mdp.policy.CategorialPolicy">CategorialPolicy</a>]</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>The final policy, if return_history is false. The</p>
              </div>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                  <code><span title="typing.Union">Union</span>[<span title="typing.List">List</span>[<a class="autorefs autorefs-internal" title="behavior_generation_lecture_python.mdp.policy.CategorialPolicy" href="../policy/#behavior_generation_lecture_python.mdp.policy.CategorialPolicy">CategorialPolicy</a>], <a class="autorefs autorefs-internal" title="behavior_generation_lecture_python.mdp.policy.CategorialPolicy" href="../policy/#behavior_generation_lecture_python.mdp.policy.CategorialPolicy">CategorialPolicy</a>]</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>history of policies as list, if return_history is true.</p>
              </div>
            </td>
          </tr>
      </tbody>
    </table>

            <details class="quote">
              <summary>Source code in <code>src/behavior_generation_lecture_python/mdp/mdp.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">528</span>
<span class="normal">529</span>
<span class="normal">530</span>
<span class="normal">531</span>
<span class="normal">532</span>
<span class="normal">533</span>
<span class="normal">534</span>
<span class="normal">535</span>
<span class="normal">536</span>
<span class="normal">537</span>
<span class="normal">538</span>
<span class="normal">539</span>
<span class="normal">540</span>
<span class="normal">541</span>
<span class="normal">542</span>
<span class="normal">543</span>
<span class="normal">544</span>
<span class="normal">545</span>
<span class="normal">546</span>
<span class="normal">547</span>
<span class="normal">548</span>
<span class="normal">549</span>
<span class="normal">550</span>
<span class="normal">551</span>
<span class="normal">552</span>
<span class="normal">553</span>
<span class="normal">554</span>
<span class="normal">555</span>
<span class="normal">556</span>
<span class="normal">557</span>
<span class="normal">558</span>
<span class="normal">559</span>
<span class="normal">560</span>
<span class="normal">561</span>
<span class="normal">562</span>
<span class="normal">563</span>
<span class="normal">564</span>
<span class="normal">565</span>
<span class="normal">566</span>
<span class="normal">567</span>
<span class="normal">568</span>
<span class="normal">569</span>
<span class="normal">570</span>
<span class="normal">571</span>
<span class="normal">572</span>
<span class="normal">573</span>
<span class="normal">574</span>
<span class="normal">575</span>
<span class="normal">576</span>
<span class="normal">577</span>
<span class="normal">578</span>
<span class="normal">579</span>
<span class="normal">580</span>
<span class="normal">581</span>
<span class="normal">582</span>
<span class="normal">583</span>
<span class="normal">584</span>
<span class="normal">585</span>
<span class="normal">586</span>
<span class="normal">587</span>
<span class="normal">588</span>
<span class="normal">589</span>
<span class="normal">590</span>
<span class="normal">591</span>
<span class="normal">592</span>
<span class="normal">593</span>
<span class="normal">594</span>
<span class="normal">595</span>
<span class="normal">596</span>
<span class="normal">597</span>
<span class="normal">598</span>
<span class="normal">599</span>
<span class="normal">600</span>
<span class="normal">601</span>
<span class="normal">602</span>
<span class="normal">603</span>
<span class="normal">604</span>
<span class="normal">605</span>
<span class="normal">606</span>
<span class="normal">607</span>
<span class="normal">608</span>
<span class="normal">609</span>
<span class="normal">610</span>
<span class="normal">611</span>
<span class="normal">612</span>
<span class="normal">613</span>
<span class="normal">614</span>
<span class="normal">615</span>
<span class="normal">616</span>
<span class="normal">617</span>
<span class="normal">618</span>
<span class="normal">619</span>
<span class="normal">620</span>
<span class="normal">621</span>
<span class="normal">622</span>
<span class="normal">623</span>
<span class="normal">624</span>
<span class="normal">625</span>
<span class="normal">626</span>
<span class="normal">627</span>
<span class="normal">628</span>
<span class="normal">629</span>
<span class="normal">630</span>
<span class="normal">631</span>
<span class="normal">632</span>
<span class="normal">633</span>
<span class="normal">634</span>
<span class="normal">635</span>
<span class="normal">636</span>
<span class="normal">637</span>
<span class="normal">638</span>
<span class="normal">639</span>
<span class="normal">640</span>
<span class="normal">641</span>
<span class="normal">642</span>
<span class="normal">643</span>
<span class="normal">644</span>
<span class="normal">645</span>
<span class="normal">646</span>
<span class="normal">647</span>
<span class="normal">648</span>
<span class="normal">649</span>
<span class="normal">650</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span> <span class="nf">policy_gradient</span><span class="p">(</span>
    <span class="o">*</span><span class="p">,</span>
    <span class="n">mdp</span><span class="p">:</span> <span class="n">MDP</span><span class="p">,</span>
    <span class="n">policy</span><span class="p">:</span> <span class="n">CategorialPolicy</span><span class="p">,</span>
    <span class="n">lr</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">1e-2</span><span class="p">,</span>
    <span class="n">iterations</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">50</span><span class="p">,</span>
    <span class="n">batch_size</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">5000</span><span class="p">,</span>
    <span class="n">return_history</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
    <span class="n">use_random_init_state</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
    <span class="n">verbose</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span><span class="p">,</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Union</span><span class="p">[</span><span class="n">List</span><span class="p">[</span><span class="n">CategorialPolicy</span><span class="p">],</span> <span class="n">CategorialPolicy</span><span class="p">]:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Train a paramterized policy using vanilla policy gradient.</span>

<span class="sd">    Adapted from: https://github.com/openai/spinningup/blob/master/spinup/examples/pytorch/pg_math/1_simple_pg.py</span>

<span class="sd">    The MIT License (MIT)</span>

<span class="sd">    Copyright (c) 2018 OpenAI (http://openai.com)</span>

<span class="sd">    Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the &quot;Software&quot;), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions:</span>

<span class="sd">    The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software.</span>

<span class="sd">    THE SOFTWARE IS PROVIDED &quot;AS IS&quot;, WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.</span>

<span class="sd">    Args:</span>
<span class="sd">        mdp: The underlying MDP.</span>
<span class="sd">        policy: The stochastic policy to be trained.</span>
<span class="sd">        lr: Learning rate.</span>
<span class="sd">        iterations: Number of iterations.</span>
<span class="sd">        batch_size: Number of samples generated for each policy update.</span>
<span class="sd">        return_history: Whether to return the whole history of value estimates</span>
<span class="sd">            instead of just the final estimate.</span>
<span class="sd">        use_random_init_state: bool, if the agent should be initialized randomly.</span>
<span class="sd">        verbose: bool, if traing progress should be printed.</span>

<span class="sd">    Returns:</span>
<span class="sd">        The final policy, if return_history is false. The</span>
<span class="sd">        history of policies as list, if return_history is true.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="mi">1337</span><span class="p">)</span>
    <span class="n">torch</span><span class="o">.</span><span class="n">manual_seed</span><span class="p">(</span><span class="mi">1337</span><span class="p">)</span>

    <span class="c1"># add untrained model to model_checkpoints</span>
    <span class="n">model_checkpoints</span> <span class="o">=</span> <span class="p">[</span><span class="n">deepcopy</span><span class="p">(</span><span class="n">policy</span><span class="p">)]</span>

    <span class="c1"># make optimizer</span>
    <span class="n">optimizer</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">optim</span><span class="o">.</span><span class="n">Adam</span><span class="p">(</span><span class="n">policy</span><span class="o">.</span><span class="n">net</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="n">lr</span><span class="o">=</span><span class="n">lr</span><span class="p">)</span>

    <span class="c1"># get non-terminal states</span>
    <span class="n">non_terminal_states</span> <span class="o">=</span> <span class="p">[</span><span class="n">state</span> <span class="k">for</span> <span class="n">state</span> <span class="ow">in</span> <span class="n">mdp</span><span class="o">.</span><span class="n">states</span> <span class="k">if</span> <span class="ow">not</span> <span class="n">mdp</span><span class="o">.</span><span class="n">is_terminal</span><span class="p">(</span><span class="n">state</span><span class="p">)]</span>

    <span class="c1"># training loop</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">iterations</span> <span class="o">+</span> <span class="mi">1</span><span class="p">):</span>
        <span class="c1"># a buffer for storing intermediate values</span>
        <span class="n">buffer</span> <span class="o">=</span> <span class="n">PolicyGradientBuffer</span><span class="p">()</span>

        <span class="c1"># reset episode-specific variables</span>
        <span class="k">if</span> <span class="n">use_random_init_state</span><span class="p">:</span>
            <span class="n">state</span> <span class="o">=</span> <span class="n">non_terminal_states</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">choice</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">non_terminal_states</span><span class="p">))]</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">state</span> <span class="o">=</span> <span class="n">mdp</span><span class="o">.</span><span class="n">initial_state</span>
        <span class="n">episode_rewards</span> <span class="o">=</span> <span class="p">[]</span>

        <span class="c1"># collect experience by acting in the mdp</span>
        <span class="k">while</span> <span class="kc">True</span><span class="p">:</span>
            <span class="c1"># save visited state</span>
            <span class="n">buffer</span><span class="o">.</span><span class="n">states</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">deepcopy</span><span class="p">(</span><span class="n">state</span><span class="p">))</span>

            <span class="c1"># call model to get next action</span>
            <span class="n">action</span> <span class="o">=</span> <span class="n">policy</span><span class="o">.</span><span class="n">get_action</span><span class="p">(</span><span class="n">state</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="n">state</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">float32</span><span class="p">))</span>

            <span class="c1"># execute action in the environment</span>
            <span class="n">state</span><span class="p">,</span> <span class="n">reward</span><span class="p">,</span> <span class="n">done</span> <span class="o">=</span> <span class="n">mdp</span><span class="o">.</span><span class="n">execute_action</span><span class="p">(</span><span class="n">state</span><span class="o">=</span><span class="n">state</span><span class="p">,</span> <span class="n">action</span><span class="o">=</span><span class="n">action</span><span class="p">)</span>

            <span class="c1"># save action, reward</span>
            <span class="n">buffer</span><span class="o">.</span><span class="n">actions</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">action</span><span class="p">)</span>
            <span class="n">episode_rewards</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">reward</span><span class="p">)</span>

            <span class="k">if</span> <span class="n">done</span><span class="p">:</span>
                <span class="c1"># if episode is over, record info about episode</span>
                <span class="n">episode_return</span> <span class="o">=</span> <span class="nb">sum</span><span class="p">(</span><span class="n">episode_rewards</span><span class="p">)</span>
                <span class="n">episode_length</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">episode_rewards</span><span class="p">)</span>
                <span class="n">buffer</span><span class="o">.</span><span class="n">episode_returns</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">episode_return</span><span class="p">)</span>
                <span class="n">buffer</span><span class="o">.</span><span class="n">episode_lengths</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">episode_length</span><span class="p">)</span>
                <span class="c1"># the weight for each logprob(a|s) is R(tau)</span>
                <span class="n">buffer</span><span class="o">.</span><span class="n">weights</span> <span class="o">+=</span> <span class="p">[</span><span class="n">episode_return</span><span class="p">]</span> <span class="o">*</span> <span class="n">episode_length</span>

                <span class="c1"># reset episode-specific variables</span>
                <span class="k">if</span> <span class="n">use_random_init_state</span><span class="p">:</span>
                    <span class="n">state</span> <span class="o">=</span> <span class="n">non_terminal_states</span><span class="p">[</span>
                        <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">choice</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">non_terminal_states</span><span class="p">))</span>
                    <span class="p">]</span>
                <span class="k">else</span><span class="p">:</span>
                    <span class="n">state</span> <span class="o">=</span> <span class="n">mdp</span><span class="o">.</span><span class="n">initial_state</span>
                <span class="n">episode_rewards</span> <span class="o">=</span> <span class="p">[]</span>

                <span class="c1"># end experience loop if we have enough of it</span>
                <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">buffer</span><span class="o">.</span><span class="n">states</span><span class="p">)</span> <span class="o">&gt;</span> <span class="n">batch_size</span><span class="p">:</span>
                    <span class="k">break</span>

        <span class="c1"># compute the loss</span>
        <span class="n">logp</span> <span class="o">=</span> <span class="n">policy</span><span class="o">.</span><span class="n">get_log_prob</span><span class="p">(</span>
            <span class="n">states</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="n">buffer</span><span class="o">.</span><span class="n">states</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">float</span><span class="p">),</span>
            <span class="n">actions</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="n">buffer</span><span class="o">.</span><span class="n">actions</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">long</span><span class="p">),</span>
        <span class="p">)</span>
        <span class="n">batch_loss</span> <span class="o">=</span> <span class="o">-</span><span class="p">(</span><span class="n">logp</span> <span class="o">*</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="n">buffer</span><span class="o">.</span><span class="n">weights</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">float</span><span class="p">))</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span>

        <span class="c1"># take a single policy gradient update step</span>
        <span class="n">optimizer</span><span class="o">.</span><span class="n">zero_grad</span><span class="p">()</span>
        <span class="n">batch_loss</span><span class="o">.</span><span class="n">backward</span><span class="p">()</span>
        <span class="n">optimizer</span><span class="o">.</span><span class="n">step</span><span class="p">()</span>

        <span class="c1"># logging</span>
        <span class="k">if</span> <span class="n">verbose</span><span class="p">:</span>
            <span class="nb">print</span><span class="p">(</span>
                <span class="sa">f</span><span class="s2">&quot;iteration: </span><span class="si">{</span><span class="n">i</span><span class="si">:</span><span class="s2">3d</span><span class="si">}</span><span class="s2">;  return: </span><span class="si">{</span><span class="n">buffer</span><span class="o">.</span><span class="n">mean_episode_return</span><span class="p">()</span><span class="si">:</span><span class="s2">.3f</span><span class="si">}</span><span class="s2">;  episode_length: </span><span class="si">{</span><span class="n">buffer</span><span class="o">.</span><span class="n">mean_episode_length</span><span class="p">()</span><span class="si">:</span><span class="s2">.3f</span><span class="si">}</span><span class="s2">&quot;</span>
            <span class="p">)</span>
        <span class="k">if</span> <span class="n">return_history</span><span class="p">:</span>
            <span class="n">model_checkpoints</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">deepcopy</span><span class="p">(</span><span class="n">policy</span><span class="p">))</span>
    <span class="k">if</span> <span class="n">return_history</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">model_checkpoints</span>
    <span class="k">return</span> <span class="n">policy</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h2 id="behavior_generation_lecture_python.mdp.mdp.q_learning" class="doc doc-heading">
            <code class="highlight language-python"><span class="n">q_learning</span><span class="p">(</span><span class="o">*</span><span class="p">,</span> <span class="n">mdp</span><span class="p">,</span> <span class="n">alpha</span><span class="p">,</span> <span class="n">epsilon</span><span class="p">,</span> <span class="n">iterations</span><span class="p">,</span> <span class="n">return_history</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span></code>

</h2>


    <div class="doc doc-contents ">

        <p>Derive a value estimate for state-action pairs by means of Q learning.</p>


<p><span class="doc-section-title">Parameters:</span></p>
    <table>
      <thead>
        <tr>
          <th>Name</th>
          <th>Type</th>
          <th>Description</th>
          <th>Default</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                <code>mdp</code>
            </td>
            <td>
                  <code><a class="autorefs autorefs-internal" title="behavior_generation_lecture_python.mdp.mdp.MDP" href="#behavior_generation_lecture_python.mdp.mdp.MDP">MDP</a></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>The underlying MDP.</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>alpha</code>
            </td>
            <td>
                  <code>float</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Learning rate.</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>epsilon</code>
            </td>
            <td>
                  <code>float</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Exploration-exploitation threshold. A random action is taken with
probability epsilon, the best action otherwise.</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>iterations</code>
            </td>
            <td>
                  <code>int</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Number of iterations.</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>return_history</code>
            </td>
            <td>
                  <code><span title="typing.Optional">Optional</span>[bool]</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Whether to return the whole history of value estimates
instead of just the final estimate.</p>
              </div>
            </td>
            <td>
                  <code>False</code>
            </td>
          </tr>
      </tbody>
    </table>


    <p><span class="doc-section-title">Returns:</span></p>
    <table>
      <thead>
        <tr>
          <th>Type</th>
          <th>Description</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                  <code><span title="typing.Union">Union</span>[<span title="behavior_generation_lecture_python.mdp.mdp.QTable">QTable</span>, <span title="typing.List">List</span>[<span title="behavior_generation_lecture_python.mdp.mdp.QTable">QTable</span>]]</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>The final value estimate, if return_history is false. The</p>
              </div>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                  <code><span title="typing.Union">Union</span>[<span title="behavior_generation_lecture_python.mdp.mdp.QTable">QTable</span>, <span title="typing.List">List</span>[<span title="behavior_generation_lecture_python.mdp.mdp.QTable">QTable</span>]]</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>history of value estimates as list, if return_history is true.</p>
              </div>
            </td>
          </tr>
      </tbody>
    </table>

            <details class="quote">
              <summary>Source code in <code>src/behavior_generation_lecture_python/mdp/mdp.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">428</span>
<span class="normal">429</span>
<span class="normal">430</span>
<span class="normal">431</span>
<span class="normal">432</span>
<span class="normal">433</span>
<span class="normal">434</span>
<span class="normal">435</span>
<span class="normal">436</span>
<span class="normal">437</span>
<span class="normal">438</span>
<span class="normal">439</span>
<span class="normal">440</span>
<span class="normal">441</span>
<span class="normal">442</span>
<span class="normal">443</span>
<span class="normal">444</span>
<span class="normal">445</span>
<span class="normal">446</span>
<span class="normal">447</span>
<span class="normal">448</span>
<span class="normal">449</span>
<span class="normal">450</span>
<span class="normal">451</span>
<span class="normal">452</span>
<span class="normal">453</span>
<span class="normal">454</span>
<span class="normal">455</span>
<span class="normal">456</span>
<span class="normal">457</span>
<span class="normal">458</span>
<span class="normal">459</span>
<span class="normal">460</span>
<span class="normal">461</span>
<span class="normal">462</span>
<span class="normal">463</span>
<span class="normal">464</span>
<span class="normal">465</span>
<span class="normal">466</span>
<span class="normal">467</span>
<span class="normal">468</span>
<span class="normal">469</span>
<span class="normal">470</span>
<span class="normal">471</span>
<span class="normal">472</span>
<span class="normal">473</span>
<span class="normal">474</span>
<span class="normal">475</span>
<span class="normal">476</span>
<span class="normal">477</span>
<span class="normal">478</span>
<span class="normal">479</span>
<span class="normal">480</span>
<span class="normal">481</span>
<span class="normal">482</span>
<span class="normal">483</span>
<span class="normal">484</span>
<span class="normal">485</span>
<span class="normal">486</span>
<span class="normal">487</span>
<span class="normal">488</span>
<span class="normal">489</span>
<span class="normal">490</span>
<span class="normal">491</span>
<span class="normal">492</span>
<span class="normal">493</span>
<span class="normal">494</span>
<span class="normal">495</span>
<span class="normal">496</span>
<span class="normal">497</span>
<span class="normal">498</span>
<span class="normal">499</span>
<span class="normal">500</span>
<span class="normal">501</span>
<span class="normal">502</span>
<span class="normal">503</span>
<span class="normal">504</span>
<span class="normal">505</span>
<span class="normal">506</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span> <span class="nf">q_learning</span><span class="p">(</span>
    <span class="o">*</span><span class="p">,</span>
    <span class="n">mdp</span><span class="p">:</span> <span class="n">MDP</span><span class="p">,</span>
    <span class="n">alpha</span><span class="p">:</span> <span class="nb">float</span><span class="p">,</span>
    <span class="n">epsilon</span><span class="p">:</span> <span class="nb">float</span><span class="p">,</span>
    <span class="n">iterations</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
    <span class="n">return_history</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">bool</span><span class="p">]</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Union</span><span class="p">[</span><span class="n">QTable</span><span class="p">,</span> <span class="n">List</span><span class="p">[</span><span class="n">QTable</span><span class="p">]]:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Derive a value estimate for state-action pairs by means of Q learning.</span>

<span class="sd">    Args:</span>
<span class="sd">        mdp: The underlying MDP.</span>
<span class="sd">        alpha: Learning rate.</span>
<span class="sd">        epsilon: Exploration-exploitation threshold. A random action is taken with</span>
<span class="sd">            probability epsilon, the best action otherwise.</span>
<span class="sd">        iterations: Number of iterations.</span>
<span class="sd">        return_history: Whether to return the whole history of value estimates</span>
<span class="sd">            instead of just the final estimate.</span>

<span class="sd">    Returns:</span>
<span class="sd">        The final value estimate, if return_history is false. The</span>
<span class="sd">        history of value estimates as list, if return_history is true.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">q_table</span> <span class="o">=</span> <span class="p">{}</span>
    <span class="k">for</span> <span class="n">state</span> <span class="ow">in</span> <span class="n">mdp</span><span class="o">.</span><span class="n">get_states</span><span class="p">():</span>
        <span class="k">for</span> <span class="n">action</span> <span class="ow">in</span> <span class="n">mdp</span><span class="o">.</span><span class="n">get_actions</span><span class="p">(</span><span class="n">state</span><span class="p">):</span>
            <span class="n">q_table</span><span class="p">[(</span><span class="n">state</span><span class="p">,</span> <span class="n">action</span><span class="p">)]</span> <span class="o">=</span> <span class="mf">0.0</span>
    <span class="n">q_table_history</span> <span class="o">=</span> <span class="p">[</span><span class="n">q_table</span><span class="o">.</span><span class="n">copy</span><span class="p">()]</span>
    <span class="n">state</span> <span class="o">=</span> <span class="n">mdp</span><span class="o">.</span><span class="n">initial_state</span>

    <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="mi">1337</span><span class="p">)</span>

    <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">iterations</span><span class="p">):</span>
        <span class="c1"># available actions:</span>
        <span class="n">avail_actions</span> <span class="o">=</span> <span class="n">mdp</span><span class="o">.</span><span class="n">get_actions</span><span class="p">(</span><span class="n">state</span><span class="p">)</span>

        <span class="c1"># choose action (exploration-exploitation trade-off)</span>
        <span class="n">rand</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">random</span><span class="p">()</span>
        <span class="k">if</span> <span class="n">rand</span> <span class="o">&lt;</span> <span class="p">(</span><span class="mi">1</span> <span class="o">-</span> <span class="n">epsilon</span><span class="p">):</span>
            <span class="n">chosen_action</span> <span class="o">=</span> <span class="n">best_action_from_q_table</span><span class="p">(</span>
                <span class="n">state</span><span class="o">=</span><span class="n">state</span><span class="p">,</span> <span class="n">available_actions</span><span class="o">=</span><span class="n">avail_actions</span><span class="p">,</span> <span class="n">q_table</span><span class="o">=</span><span class="n">q_table</span>
            <span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">chosen_action</span> <span class="o">=</span> <span class="n">random_action</span><span class="p">(</span><span class="n">avail_actions</span><span class="p">)</span>

        <span class="c1"># interact with environment</span>
        <span class="n">next_state</span> <span class="o">=</span> <span class="n">mdp</span><span class="o">.</span><span class="n">sample_next_state</span><span class="p">(</span><span class="n">state</span><span class="p">,</span> <span class="n">chosen_action</span><span class="p">)</span>

        <span class="c1"># update Q table</span>
        <span class="n">greedy_value_estimate_next_state</span> <span class="o">=</span> <span class="n">greedy_value_estimate_for_state</span><span class="p">(</span>
            <span class="n">q_table</span><span class="o">=</span><span class="n">q_table</span><span class="p">,</span> <span class="n">state</span><span class="o">=</span><span class="n">next_state</span>
        <span class="p">)</span>
        <span class="n">q_table</span><span class="p">[(</span><span class="n">state</span><span class="p">,</span> <span class="n">chosen_action</span><span class="p">)]</span> <span class="o">=</span> <span class="p">(</span><span class="mi">1</span> <span class="o">-</span> <span class="n">alpha</span><span class="p">)</span> <span class="o">*</span> <span class="n">q_table</span><span class="p">[</span>
            <span class="p">(</span><span class="n">state</span><span class="p">,</span> <span class="n">chosen_action</span><span class="p">)</span>
        <span class="p">]</span> <span class="o">+</span> <span class="n">alpha</span> <span class="o">*</span> <span class="p">(</span><span class="n">mdp</span><span class="o">.</span><span class="n">get_reward</span><span class="p">(</span><span class="n">next_state</span><span class="p">)</span> <span class="o">+</span> <span class="n">greedy_value_estimate_next_state</span><span class="p">)</span>

        <span class="k">if</span> <span class="n">return_history</span><span class="p">:</span>
            <span class="n">q_table_history</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">q_table</span><span class="o">.</span><span class="n">copy</span><span class="p">())</span>

        <span class="k">if</span> <span class="n">mdp</span><span class="o">.</span><span class="n">is_terminal</span><span class="p">(</span><span class="n">next_state</span><span class="p">):</span>
            <span class="n">state</span> <span class="o">=</span> <span class="n">mdp</span><span class="o">.</span><span class="n">initial_state</span>  <span class="c1"># restart</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">state</span> <span class="o">=</span> <span class="n">next_state</span>  <span class="c1"># continue</span>

    <span class="k">if</span> <span class="n">return_history</span><span class="p">:</span>
        <span class="n">utility_history</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="k">for</span> <span class="n">q_tab</span> <span class="ow">in</span> <span class="n">q_table_history</span><span class="p">:</span>
            <span class="n">utility_history</span><span class="o">.</span><span class="n">append</span><span class="p">(</span>
                <span class="p">{</span>
                    <span class="n">state</span><span class="p">:</span> <span class="n">greedy_value_estimate_for_state</span><span class="p">(</span><span class="n">q_table</span><span class="o">=</span><span class="n">q_tab</span><span class="p">,</span> <span class="n">state</span><span class="o">=</span><span class="n">state</span><span class="p">)</span>
                    <span class="k">for</span> <span class="n">state</span> <span class="ow">in</span> <span class="n">mdp</span><span class="o">.</span><span class="n">get_states</span><span class="p">()</span>
                <span class="p">}</span>
            <span class="p">)</span>
        <span class="k">return</span> <span class="n">utility_history</span>

    <span class="k">return</span> <span class="p">{</span>
        <span class="n">state</span><span class="p">:</span> <span class="n">greedy_value_estimate_for_state</span><span class="p">(</span><span class="n">q_table</span><span class="o">=</span><span class="n">q_table</span><span class="p">,</span> <span class="n">state</span><span class="o">=</span><span class="n">state</span><span class="p">)</span>
        <span class="k">for</span> <span class="n">state</span> <span class="ow">in</span> <span class="n">mdp</span><span class="o">.</span><span class="n">get_states</span><span class="p">()</span>
    <span class="p">}</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h2 id="behavior_generation_lecture_python.mdp.mdp.random_action" class="doc doc-heading">
            <code class="highlight language-python"><span class="n">random_action</span><span class="p">(</span><span class="n">available_actions</span><span class="p">)</span></code>

</h2>


    <div class="doc doc-contents ">

        <p>Derive a random action from the set of available actions.</p>


<p><span class="doc-section-title">Parameters:</span></p>
    <table>
      <thead>
        <tr>
          <th>Name</th>
          <th>Type</th>
          <th>Description</th>
          <th>Default</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                <code>available_actions</code>
            </td>
            <td>
                  <code><span title="typing.Set">Set</span>[<span title="typing.Any">Any</span>]</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Set of available actions.</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
      </tbody>
    </table>


    <p><span class="doc-section-title">Returns:</span></p>
    <table>
      <thead>
        <tr>
          <th>Type</th>
          <th>Description</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                  <code><span title="typing.Any">Any</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>A random action.</p>
              </div>
            </td>
          </tr>
      </tbody>
    </table>

            <details class="quote">
              <summary>Source code in <code>src/behavior_generation_lecture_python/mdp/mdp.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">397</span>
<span class="normal">398</span>
<span class="normal">399</span>
<span class="normal">400</span>
<span class="normal">401</span>
<span class="normal">402</span>
<span class="normal">403</span>
<span class="normal">404</span>
<span class="normal">405</span>
<span class="normal">406</span>
<span class="normal">407</span>
<span class="normal">408</span>
<span class="normal">409</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span> <span class="nf">random_action</span><span class="p">(</span><span class="n">available_actions</span><span class="p">:</span> <span class="n">Set</span><span class="p">[</span><span class="n">Any</span><span class="p">])</span> <span class="o">-&gt;</span> <span class="n">Any</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Derive a random action from the set of available actions.</span>

<span class="sd">    Args:</span>
<span class="sd">        available_actions: Set of available actions.</span>

<span class="sd">    Returns:</span>
<span class="sd">        A random action.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">available_actions_list</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="n">available_actions</span><span class="p">)</span>
    <span class="n">num_actions</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">available_actions_list</span><span class="p">)</span>
    <span class="n">choice</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">choice</span><span class="p">(</span><span class="n">num_actions</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">available_actions_list</span><span class="p">[</span><span class="n">choice</span><span class="p">]</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h2 id="behavior_generation_lecture_python.mdp.mdp.value_iteration" class="doc doc-heading">
            <code class="highlight language-python"><span class="n">value_iteration</span><span class="p">(</span><span class="n">mdp</span><span class="p">,</span> <span class="n">epsilon</span><span class="p">,</span> <span class="n">max_iterations</span><span class="p">,</span> <span class="n">return_history</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span></code>

</h2>


    <div class="doc doc-contents ">

        <p>Derive a utility estimate by means of value iteration.</p>


<p><span class="doc-section-title">Parameters:</span></p>
    <table>
      <thead>
        <tr>
          <th>Name</th>
          <th>Type</th>
          <th>Description</th>
          <th>Default</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                <code>mdp</code>
            </td>
            <td>
                  <code><a class="autorefs autorefs-internal" title="behavior_generation_lecture_python.mdp.mdp.MDP" href="#behavior_generation_lecture_python.mdp.mdp.MDP">MDP</a></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>The underlying MDP.</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>epsilon</code>
            </td>
            <td>
                  <code>float</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Termination criterion: if maximum difference in utility
update is below epsilon, the iteration is terminated.</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>max_iterations</code>
            </td>
            <td>
                  <code>int</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Maximum number of iterations, if exceeded,
RuntimeError is raised.</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>return_history</code>
            </td>
            <td>
                  <code><span title="typing.Optional">Optional</span>[bool]</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Whether to return the whole history of utilities
instead of just the final estimate.</p>
              </div>
            </td>
            <td>
                  <code>False</code>
            </td>
          </tr>
      </tbody>
    </table>


    <p><span class="doc-section-title">Returns:</span></p>
    <table>
      <thead>
        <tr>
          <th>Type</th>
          <th>Description</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                  <code><span title="typing.Union">Union</span>[<span title="behavior_generation_lecture_python.mdp.mdp.StateValueTable">StateValueTable</span>, <span title="typing.List">List</span>[<span title="behavior_generation_lecture_python.mdp.mdp.StateValueTable">StateValueTable</span>]]</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>The final utility estimate, if return_history is false. The</p>
              </div>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                  <code><span title="typing.Union">Union</span>[<span title="behavior_generation_lecture_python.mdp.mdp.StateValueTable">StateValueTable</span>, <span title="typing.List">List</span>[<span title="behavior_generation_lecture_python.mdp.mdp.StateValueTable">StateValueTable</span>]]</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>history of utility estimates as list, if return_history is true.</p>
              </div>
            </td>
          </tr>
      </tbody>
    </table>

            <details class="quote">
              <summary>Source code in <code>src/behavior_generation_lecture_python/mdp/mdp.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">332</span>
<span class="normal">333</span>
<span class="normal">334</span>
<span class="normal">335</span>
<span class="normal">336</span>
<span class="normal">337</span>
<span class="normal">338</span>
<span class="normal">339</span>
<span class="normal">340</span>
<span class="normal">341</span>
<span class="normal">342</span>
<span class="normal">343</span>
<span class="normal">344</span>
<span class="normal">345</span>
<span class="normal">346</span>
<span class="normal">347</span>
<span class="normal">348</span>
<span class="normal">349</span>
<span class="normal">350</span>
<span class="normal">351</span>
<span class="normal">352</span>
<span class="normal">353</span>
<span class="normal">354</span>
<span class="normal">355</span>
<span class="normal">356</span>
<span class="normal">357</span>
<span class="normal">358</span>
<span class="normal">359</span>
<span class="normal">360</span>
<span class="normal">361</span>
<span class="normal">362</span>
<span class="normal">363</span>
<span class="normal">364</span>
<span class="normal">365</span>
<span class="normal">366</span>
<span class="normal">367</span>
<span class="normal">368</span>
<span class="normal">369</span>
<span class="normal">370</span>
<span class="normal">371</span>
<span class="normal">372</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span> <span class="nf">value_iteration</span><span class="p">(</span>
    <span class="n">mdp</span><span class="p">:</span> <span class="n">MDP</span><span class="p">,</span>
    <span class="n">epsilon</span><span class="p">:</span> <span class="nb">float</span><span class="p">,</span>
    <span class="n">max_iterations</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
    <span class="n">return_history</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">bool</span><span class="p">]</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Union</span><span class="p">[</span><span class="n">StateValueTable</span><span class="p">,</span> <span class="n">List</span><span class="p">[</span><span class="n">StateValueTable</span><span class="p">]]:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Derive a utility estimate by means of value iteration.</span>

<span class="sd">    Args:</span>
<span class="sd">        mdp: The underlying MDP.</span>
<span class="sd">        epsilon: Termination criterion: if maximum difference in utility</span>
<span class="sd">            update is below epsilon, the iteration is terminated.</span>
<span class="sd">        max_iterations: Maximum number of iterations, if exceeded,</span>
<span class="sd">            RuntimeError is raised.</span>
<span class="sd">        return_history: Whether to return the whole history of utilities</span>
<span class="sd">            instead of just the final estimate.</span>

<span class="sd">    Returns:</span>
<span class="sd">        The final utility estimate, if return_history is false. The</span>
<span class="sd">        history of utility estimates as list, if return_history is true.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">utility</span> <span class="o">=</span> <span class="p">{</span><span class="n">state</span><span class="p">:</span> <span class="mf">0.0</span> <span class="k">for</span> <span class="n">state</span> <span class="ow">in</span> <span class="n">mdp</span><span class="o">.</span><span class="n">get_states</span><span class="p">()}</span>
    <span class="n">utility_history</span> <span class="o">=</span> <span class="p">[</span><span class="n">utility</span><span class="o">.</span><span class="n">copy</span><span class="p">()]</span>
    <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">max_iterations</span><span class="p">):</span>
        <span class="n">utility_old</span> <span class="o">=</span> <span class="n">utility</span><span class="o">.</span><span class="n">copy</span><span class="p">()</span>
        <span class="n">max_delta</span> <span class="o">=</span> <span class="mf">0.0</span>
        <span class="k">for</span> <span class="n">state</span> <span class="ow">in</span> <span class="n">mdp</span><span class="o">.</span><span class="n">get_states</span><span class="p">():</span>
            <span class="n">utility</span><span class="p">[</span><span class="n">state</span><span class="p">]</span> <span class="o">=</span> <span class="nb">max</span><span class="p">(</span>
                <span class="n">expected_utility_of_action</span><span class="p">(</span>
                    <span class="n">mdp</span><span class="p">,</span> <span class="n">state</span><span class="o">=</span><span class="n">state</span><span class="p">,</span> <span class="n">action</span><span class="o">=</span><span class="n">action</span><span class="p">,</span> <span class="n">utility_of_states</span><span class="o">=</span><span class="n">utility_old</span>
                <span class="p">)</span>
                <span class="k">for</span> <span class="n">action</span> <span class="ow">in</span> <span class="n">mdp</span><span class="o">.</span><span class="n">get_actions</span><span class="p">(</span><span class="n">state</span><span class="p">)</span>
            <span class="p">)</span>
            <span class="n">max_delta</span> <span class="o">=</span> <span class="nb">max</span><span class="p">(</span><span class="n">max_delta</span><span class="p">,</span> <span class="nb">abs</span><span class="p">(</span><span class="n">utility</span><span class="p">[</span><span class="n">state</span><span class="p">]</span> <span class="o">-</span> <span class="n">utility_old</span><span class="p">[</span><span class="n">state</span><span class="p">]))</span>
        <span class="k">if</span> <span class="n">return_history</span><span class="p">:</span>
            <span class="n">utility_history</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">utility</span><span class="o">.</span><span class="n">copy</span><span class="p">())</span>
        <span class="k">if</span> <span class="n">max_delta</span> <span class="o">&lt;</span> <span class="n">epsilon</span><span class="p">:</span>
            <span class="k">if</span> <span class="n">return_history</span><span class="p">:</span>
                <span class="k">return</span> <span class="n">utility_history</span>
            <span class="k">return</span> <span class="n">utility</span>
    <span class="k">raise</span> <span class="ne">RuntimeError</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Did not converge in </span><span class="si">{</span><span class="n">max_iterations</span><span class="si">}</span><span class="s2"> iterations&quot;</span><span class="p">)</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>



  </div>

    </div>

</div>












                
              </article>
            </div>
          
          
<script>var target=document.getElementById(location.hash.slice(1));target&&target.name&&(target.checked=target.name.startsWith("__tabbed_"))</script>
        </div>
        
      </main>
      
        <footer class="md-footer">
  
  <div class="md-footer-meta md-typeset">
    <div class="md-footer-meta__inner md-grid">
      <div class="md-copyright">
  
    <div class="md-copyright__highlight">
      Copyright &copy; 2015 - present, Organizers of the lecture Decision-Making and Motion Planning for Automated Driving at KIT
    </div>
  
  
    Made with
    <a href="https://squidfunk.github.io/mkdocs-material/" target="_blank" rel="noopener">
      Material for MkDocs
    </a>
  
</div>
      
    </div>
  </div>
</footer>
      
    </div>
    <div class="md-dialog" data-md-component="dialog">
      <div class="md-dialog__inner md-typeset"></div>
    </div>
    
    
    <script id="__config" type="application/json">{"base": "../../../..", "features": [], "search": "../../../../assets/javascripts/workers/search.6ce7567c.min.js", "translations": {"clipboard.copied": "Copied to clipboard", "clipboard.copy": "Copy to clipboard", "search.result.more.one": "1 more on this page", "search.result.more.other": "# more on this page", "search.result.none": "No matching documents", "search.result.one": "1 matching document", "search.result.other": "# matching documents", "search.result.placeholder": "Type to start searching", "search.result.term.missing": "Missing", "select.version": "Select version"}}</script>
    
    
      <script src="../../../../assets/javascripts/bundle.88dd0f4e.min.js"></script>
      
    
  </body>
</html>